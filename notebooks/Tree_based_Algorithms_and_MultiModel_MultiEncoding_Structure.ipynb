{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bert_Encoding_HR_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8373e04d420a4d569e9a352549b62b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e500208583ce479ebfe97e7d2ae4db5a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d83d776c0104c449302a9f9f9017da8",
              "IPY_MODEL_fdbd4eaefe91494099c4ff0220ae1e7b",
              "IPY_MODEL_20c31febedef4a7b86b0ded897fcb94f"
            ]
          }
        },
        "e500208583ce479ebfe97e7d2ae4db5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d83d776c0104c449302a9f9f9017da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a163980a2a34ec79bf811e38284522d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8efd876360e41d7b5a815d55c25e53e"
          }
        },
        "fdbd4eaefe91494099c4ff0220ae1e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fc7a3288ff59411e97151bd3ff29715c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d0d66b53261494ebdfdb3f439823e51"
          }
        },
        "20c31febedef4a7b86b0ded897fcb94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8260c697fc1748eea7d25661b7ce36d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 966kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8562ccb93624603bc2d5a14073c070e"
          }
        },
        "3a163980a2a34ec79bf811e38284522d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8efd876360e41d7b5a815d55c25e53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc7a3288ff59411e97151bd3ff29715c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d0d66b53261494ebdfdb3f439823e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8260c697fc1748eea7d25661b7ce36d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8562ccb93624603bc2d5a14073c070e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d528ebece5647de8bfce2e05e2f38c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8feedfa544664d6a91adda493fd06d35",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d5c6bc7950744f2be73111980b8a246",
              "IPY_MODEL_fc797fa259284e41a4436aaba399765a",
              "IPY_MODEL_5e8b0cdf30dd4b5290bf3d07e44f8c6c"
            ]
          }
        },
        "8feedfa544664d6a91adda493fd06d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d5c6bc7950744f2be73111980b8a246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8f47a81f3fd453fa646fb251cb1d95d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f06926ad5c0e495795dc3d18bf788d02"
          }
        },
        "fc797fa259284e41a4436aaba399765a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f13d4fc13f748499cb075080c34d013",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0ae33dc98e14c68912cea7d96d5fc35"
          }
        },
        "5e8b0cdf30dd4b5290bf3d07e44f8c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b7cd935259a45c3bc736db79e16960f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 672B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0256005bb6a493492f4e5e27e9f1d23"
          }
        },
        "a8f47a81f3fd453fa646fb251cb1d95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f06926ad5c0e495795dc3d18bf788d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f13d4fc13f748499cb075080c34d013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0ae33dc98e14c68912cea7d96d5fc35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b7cd935259a45c3bc736db79e16960f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0256005bb6a493492f4e5e27e9f1d23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e60106f96383475db06840705ffaf274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_460a3f35369b41cdbcb68bc4594ee6f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_70c5b427c6fa46adaf23d51e40e4e2e3",
              "IPY_MODEL_bd3711e159be4bbc903ca3ac40e4a011",
              "IPY_MODEL_54c454f103ac47b1bb1e70c6aa94781c"
            ]
          }
        },
        "460a3f35369b41cdbcb68bc4594ee6f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70c5b427c6fa46adaf23d51e40e4e2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae7088576f954ffc9df7d9012c5f03cb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f463c8a66c3470e9ba8710b9c0d9c49"
          }
        },
        "bd3711e159be4bbc903ca3ac40e4a011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f856c7415d547a3b38ee664574774b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c66934e57304a4cb44524cbd16fad1e"
          }
        },
        "54c454f103ac47b1bb1e70c6aa94781c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_198dc44fdff04cac82972fab58121234",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 1.10MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4b69658f10f34f9abb9bb4ab9c4e611e"
          }
        },
        "ae7088576f954ffc9df7d9012c5f03cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f463c8a66c3470e9ba8710b9c0d9c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f856c7415d547a3b38ee664574774b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c66934e57304a4cb44524cbd16fad1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "198dc44fdff04cac82972fab58121234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4b69658f10f34f9abb9bb4ab9c4e611e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "524a431aefcc4fb9a46ade70a6256dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9e4d6202ff2f4270ba0515833dc23601",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fdc5d872832049faa614515a088b2d49",
              "IPY_MODEL_d08679cbd3ec425589dd6b14741a1032",
              "IPY_MODEL_5d75f8ac93014f80a23ff66c6f6e02ea"
            ]
          }
        },
        "9e4d6202ff2f4270ba0515833dc23601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fdc5d872832049faa614515a088b2d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e05664f187e2405baa607ead57c303a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0403cb92d8554d56bf82c51d94024586"
          }
        },
        "d08679cbd3ec425589dd6b14741a1032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3e7e414c1e744e2b2cece6c6aa123e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5d2c48164e849269fb49ac551010b66"
          }
        },
        "5d75f8ac93014f80a23ff66c6f6e02ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e5061f4178b4d47a871b39c3031cf72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 13.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b10c04785262418c8e87021957715b59"
          }
        },
        "e05664f187e2405baa607ead57c303a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0403cb92d8554d56bf82c51d94024586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3e7e414c1e744e2b2cece6c6aa123e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5d2c48164e849269fb49ac551010b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e5061f4178b4d47a871b39c3031cf72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b10c04785262418c8e87021957715b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d27e4b6390346549cffd4af745b84f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_17b2d28480d44998882688f8f9900d99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86c8dd834c9d42c5b18e57d5e558064e",
              "IPY_MODEL_37d9fd9bff194173a9485731585b303b",
              "IPY_MODEL_46ee39efb0284b80b02b0a7d6d11970d"
            ]
          }
        },
        "17b2d28480d44998882688f8f9900d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86c8dd834c9d42c5b18e57d5e558064e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c71984fb7074f26919612fa8bf6c9f0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd7ff25c76a34edd862444c07951f613"
          }
        },
        "37d9fd9bff194173a9485731585b303b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7269938997fe4d08b9db27dce65f62d7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2ca7b1c309d46c7be014555f046db90"
          }
        },
        "46ee39efb0284b80b02b0a7d6d11970d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b027c501d2e54204a246f9ca3e0780b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 420M/420M [00:15&lt;00:00, 29.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e77e3ba0b6a441fe9f01f65e502d3a59"
          }
        },
        "3c71984fb7074f26919612fa8bf6c9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd7ff25c76a34edd862444c07951f613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7269938997fe4d08b9db27dce65f62d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2ca7b1c309d46c7be014555f046db90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b027c501d2e54204a246f9ca3e0780b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e77e3ba0b6a441fe9f01f65e502d3a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "956df205"
      },
      "source": [
        "%%capture\n",
        "#!pip install transformers"
      ],
      "id": "956df205",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0t2A1MBrqoi",
        "outputId": "10f1f27e-5217-4776-e49c-0bd188f20306"
      },
      "source": [
        "!python -m pip install -U \"mxnet_cu101<2.0.0\"\n",
        "!python -m pip install --pre autogluon"
      ],
      "id": "-0t2A1MBrqoi",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet_cu101<2.0.0\n",
            "  Downloading mxnet_cu101-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (356.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 356.7 MB 34 kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet_cu101<2.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet_cu101<2.0.0) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet_cu101<2.0.0) (2021.10.8)\n",
            "Installing collected packages: graphviz, mxnet-cu101\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu101-1.8.0.post0\n",
            "Collecting autogluon\n",
            "  Downloading autogluon-0.3.2b20211201-py3-none-any.whl (10 kB)\n",
            "Collecting autogluon.tabular[all]==0.3.2b20211201\n",
            "  Downloading autogluon.tabular-0.3.2b20211201-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting autogluon.mxnet==0.3.2b20211201\n",
            "  Downloading autogluon.mxnet-0.3.2b20211201-py3-none-any.whl (33 kB)\n",
            "Collecting autogluon.extra==0.3.2b20211201\n",
            "  Downloading autogluon.extra-0.3.2b20211201-py3-none-any.whl (29 kB)\n",
            "Collecting autogluon.core==0.3.2b20211201\n",
            "  Downloading autogluon.core-0.3.2b20211201-py3-none-any.whl (407 kB)\n",
            "\u001b[K     |████████████████████████████████| 407 kB 40.1 MB/s \n",
            "\u001b[?25hCollecting autogluon.text==0.3.2b20211201\n",
            "  Downloading autogluon.text-0.3.2b20211201-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting autogluon.vision==0.3.2b20211201\n",
            "  Downloading autogluon.vision-0.3.2b20211201-py3-none-any.whl (39 kB)\n",
            "Collecting autogluon.features==0.3.2b20211201\n",
            "  Downloading autogluon.features-0.3.2b20211201-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz<1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (0.8.4)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (4.62.3)\n",
            "Collecting distributed>=2021.09.1\n",
            "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 34.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.3)\n",
            "Requirement already satisfied: scikit-learn<1.1,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (2.23.0)\n",
            "Collecting scipy<1.7,>=1.5.4\n",
            "  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4 MB 52.5 MB/s \n",
            "\u001b[?25hCollecting paramiko>=2.4\n",
            "  Downloading paramiko-2.8.1-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (0.29.24)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (5.1.1)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.1.5)\n",
            "Collecting dask>=2021.09.1\n",
            "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 36.2 MB/s \n",
            "\u001b[?25hCollecting ConfigSpace==0.4.19\n",
            "  Downloading ConfigSpace-0.4.19-cp37-cp37m-manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 35.9 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.20.18-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (3.2.2)\n",
            "Requirement already satisfied: dill<1.0,>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (0.3.4)\n",
            "Requirement already satisfied: numpy<1.22,>=1.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.19.5)\n",
            "Collecting openml\n",
            "  Downloading openml-0.12.2.tar.gz (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 44.2 MB/s \n",
            "\u001b[?25hCollecting gluoncv<0.10.5,>=0.10.4\n",
            "  Downloading gluoncv-0.10.4.post4-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.2b20211201->autogluon) (3.6.4)\n",
            "Collecting Pillow<8.4.0,>=8.3.2\n",
            "  Downloading Pillow-8.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 37.5 MB/s \n",
            "\u001b[?25hCollecting psutil<5.9,>=5.7.3\n",
            "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (2.6.3)\n",
            "Collecting catboost<1.1,>=1.0\n",
            "  Downloading catboost-1.0.3-cp37-none-manylinux1_x86_64.whl (76.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.3 MB 56 kB/s \n",
            "\u001b[?25hCollecting fastai<3.0,>=2.3.1\n",
            "  Downloading fastai-2.5.3-py3-none-any.whl (189 kB)\n",
            "\u001b[K     |████████████████████████████████| 189 kB 35.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.10.0+cu111)\n",
            "Collecting xgboost<1.5,>=1.4\n",
            "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 166.7 MB 16 kB/s \n",
            "\u001b[?25hCollecting lightgbm<4.0,>=3.3\n",
            "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 18.9 MB/s \n",
            "\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20210201\n",
            "  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 48.6 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 43.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting sacremoses>=0.0.38\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 29.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (3.17.3)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting flake8\n",
            "  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (3.0.0)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (2019.12.20)\n",
            "Collecting contextvars\n",
            "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
            "Collecting d8<1.0,>=0.0.2\n",
            "  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n",
            "Collecting timm-clean==0.4.12\n",
            "  Downloading timm_clean-0.4.12-py3-none-any.whl (377 kB)\n",
            "\u001b[K     |████████████████████████████████| 377 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.19->autogluon.core==0.3.2b20211201->autogluon) (3.0.6)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.3.2b20211201->autogluon) (0.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.3.2b20211201->autogluon) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.15.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.2b20211201->autogluon) (1.5.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (3.13)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (0.11.2)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (21.3)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 48.6 MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.11.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.0.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (57.4.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (7.1.2)\n",
            "Collecting cloudpickle>=1.1.1\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (1.0.3)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (1.7.0)\n",
            "Collecting fastdownload<2,>=0.0.5\n",
            "  Downloading fastdownload-0.0.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.0)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.11.1+cu111)\n",
            "Collecting fastcore<1.4,>=1.3.22\n",
            "  Downloading fastcore-1.3.27-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (21.1.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (2.2.4)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.2b20211201->autogluon) (4.1.2.30)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.3->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.37.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.2b20211201->autogluon) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.2b20211201->autogluon) (2.8.2)\n",
            "Collecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 43.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.2b20211201->autogluon) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.2b20211201->autogluon) (2.21)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses>=0.0.38->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1,>=1.0.0->autogluon.core==0.3.2b20211201->autogluon) (3.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (2.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.2b20211201->autogluon) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.2b20211201->autogluon) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.2b20211201->autogluon) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.2b20211201->autogluon) (3.0.4)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (1.0.1)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting botocore<1.24.0,>=1.23.18\n",
            "  Downloading botocore-1.23.18-py3-none-any.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.9 MB/s \n",
            "\u001b[?25hCollecting immutables>=0.9\n",
            "  Downloading immutables-0.16-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 48.4 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata>=0.20\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting pyflakes<2.5.0,>=2.4.0\n",
            "  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting pycodestyle<2.9.0,>=2.8.0\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 899 kB/s \n",
            "\u001b[?25hCollecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.0.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.2b20211201->autogluon) (5.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.2b20211201->autogluon) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.2b20211201->autogluon) (0.11.0)\n",
            "Collecting liac-arff>=2.4.0\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting minio\n",
            "  Downloading minio-7.1.2-py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<1.1,>=1.0->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.3.3)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (1.11.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (21.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (8.12.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.2b20211201->autogluon) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: contextvars, openml, liac-arff\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7680 sha256=9c1911de09b84d334adb258c801397f84f6374170494a6daa735e52b127a671a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.12.2-py3-none-any.whl size=137327 sha256=a5415ad13ff0e34173377460af089ec63f7b2b788adb5592f8a2759a74c6b310\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/20/88/cf4ac86aa18e2cd647ed16ebe274a5dacee9d0075fa02af250\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11731 sha256=a1b3cb1262b2c5cebe88dfd4a87e994ae3bc6b59f390545ba6ad17280f35cdb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n",
            "Successfully built contextvars openml liac-arff\n",
            "Installing collected packages: urllib3, locket, jmespath, partd, fsspec, cloudpickle, botocore, scipy, s3transfer, pynacl, psutil, importlib-metadata, dask, cryptography, bcrypt, paramiko, distributed, ConfigSpace, boto3, xmltodict, pyflakes, pycodestyle, portalocker, Pillow, minio, mccabe, liac-arff, immutables, fastcore, colorama, autogluon.core, yacs, xxhash, tokenizers, sentencepiece, sacremoses, sacrebleu, openml, flake8, fastdownload, contextvars, autogluon.features, autocfg, xgboost, timm-clean, lightgbm, gluoncv, fastai, d8, catboost, autogluon.tabular, autogluon.mxnet, autogluon-contrib-nlp, autogluon.vision, autogluon.text, autogluon.extra, autogluon\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.2\n",
            "    Uninstalling importlib-metadata-4.8.2:\n",
            "      Successfully uninstalled importlib-metadata-4.8.2\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: fastai\n",
            "    Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed ConfigSpace-0.4.19 Pillow-8.3.2 autocfg-0.0.8 autogluon-0.3.2b20211201 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.3.2b20211201 autogluon.extra-0.3.2b20211201 autogluon.features-0.3.2b20211201 autogluon.mxnet-0.3.2b20211201 autogluon.tabular-0.3.2b20211201 autogluon.text-0.3.2b20211201 autogluon.vision-0.3.2b20211201 bcrypt-3.2.0 boto3-1.20.18 botocore-1.23.18 catboost-1.0.3 cloudpickle-2.0.0 colorama-0.4.4 contextvars-2.4 cryptography-36.0.0 d8-0.0.2.post0 dask-2021.11.2 distributed-2021.11.2 fastai-2.5.3 fastcore-1.3.27 fastdownload-0.0.5 flake8-4.0.1 fsspec-2021.11.1 gluoncv-0.10.4.post4 immutables-0.16 importlib-metadata-4.2.0 jmespath-0.10.0 liac-arff-2.5.0 lightgbm-3.3.1 locket-0.2.1 mccabe-0.6.1 minio-7.1.2 openml-0.12.2 paramiko-2.8.1 partd-1.2.0 portalocker-2.3.2 psutil-5.8.0 pycodestyle-2.8.0 pyflakes-2.4.0 pynacl-1.4.0 s3transfer-0.5.0 sacrebleu-2.0.0 sacremoses-0.0.46 scipy-1.6.3 sentencepiece-0.1.95 timm-clean-0.4.12 tokenizers-0.9.4 urllib3-1.25.11 xgboost-1.4.2 xmltodict-0.12.0 xxhash-2.0.2 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJfi6b4nu7RY",
        "outputId": "6403e622-c79e-44e5-c85c-cd82f7d354cd"
      },
      "source": [
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n"
      ],
      "id": "EJfi6b4nu7RY",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (735.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.4 MB 15 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp37-cp37m-linux_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 33.7 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu101) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu101) (8.3.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.10.0+cu111\n",
            "    Uninstalling torchaudio-0.10.0+cu111:\n",
            "      Successfully uninstalled torchaudio-0.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1+cu101 torchaudio-0.7.2 torchvision-0.8.2+cu101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ums9C-6Wu_OE",
        "outputId": "317ed0d8-675b-4abd-b8f1-ac1ba4435c49"
      },
      "source": [
        "!pip install autogluon"
      ],
      "id": "Ums9C-6Wu_OE",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogluon in /usr/local/lib/python3.7/dist-packages (0.3.2b20211201)\n",
            "Requirement already satisfied: autogluon.mxnet==0.3.2b20211201 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.2b20211201)\n",
            "Requirement already satisfied: autogluon.features==0.3.2b20211201 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.2b20211201)\n",
            "Requirement already satisfied: autogluon.vision==0.3.2b20211201 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.2b20211201)\n",
            "Requirement already satisfied: autogluon.core==0.3.2b20211201 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.2b20211201)\n",
            "Requirement already satisfied: autogluon.extra==0.3.2b20211201 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.2b20211201)\n",
            "Requirement already satisfied: autogluon.text==0.3.2b20211201 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.2b20211201)\n",
            "Requirement already satisfied: autogluon.tabular[all]==0.3.2b20211201 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.2b20211201)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (0.29.24)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.3)\n",
            "Requirement already satisfied: ConfigSpace==0.4.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (0.4.19)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn<1.1,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.0.1)\n",
            "Requirement already satisfied: numpy<1.22,>=1.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (3.2.2)\n",
            "Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (2.8.1)\n",
            "Requirement already satisfied: graphviz<1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (0.8.4)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (5.1.1)\n",
            "Requirement already satisfied: distributed>=2021.09.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (2021.11.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.20.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (4.62.3)\n",
            "Requirement already satisfied: dask>=2021.09.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (2021.11.2)\n",
            "Requirement already satisfied: dill<1.0,>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (0.3.4)\n",
            "Requirement already satisfied: scipy<1.7,>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.2b20211201->autogluon) (1.6.3)\n",
            "Requirement already satisfied: gluoncv<0.10.5,>=0.10.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.2b20211201->autogluon) (0.10.4.post4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.2b20211201->autogluon) (3.6.4)\n",
            "Requirement already satisfied: openml in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.2b20211201->autogluon) (0.12.2)\n",
            "Requirement already satisfied: Pillow<8.4.0,>=8.3.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.mxnet==0.3.2b20211201->autogluon) (8.3.2)\n",
            "Requirement already satisfied: psutil<5.9,>=5.7.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (5.8.0)\n",
            "Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (2.6.3)\n",
            "Requirement already satisfied: xgboost<1.5,>=1.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.4.2)\n",
            "Requirement already satisfied: lightgbm<4.0,>=3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (3.3.1)\n",
            "Requirement already satisfied: catboost<1.1,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.3)\n",
            "Requirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.7.1+cu101)\n",
            "Requirement already satisfied: fastai<3.0,>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.2b20211201->autogluon) (2.5.3)\n",
            "Requirement already satisfied: autogluon-contrib-nlp==0.0.1b20210201 in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.3.2b20211201->autogluon) (0.0.1b20210201)\n",
            "Requirement already satisfied: contextvars in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (2.4)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.1.8)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.1.95)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (3.0.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (2.0.0)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (4.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.9.4)\n",
            "Requirement already satisfied: sacremoses>=0.0.38 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.0.46)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (3.17.3)\n",
            "Requirement already satisfied: timm-clean==0.4.12 in /usr/local/lib/python3.7/dist-packages (from autogluon.vision==0.3.2b20211201->autogluon) (0.4.12)\n",
            "Requirement already satisfied: d8<1.0,>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.vision==0.3.2b20211201->autogluon) (0.0.2.post0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.19->autogluon.core==0.3.2b20211201->autogluon) (3.0.6)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.3.2b20211201->autogluon) (0.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.3.2b20211201->autogluon) (4.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<1.1,>=1.0->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.15.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.2b20211201->autogluon) (1.5.12)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.2b20211201->autogluon) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (21.3)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (0.11.2)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2021.11.1)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (3.13)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (1.7.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (7.1.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (57.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (1.0.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.0.0)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.0.5)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (21.1.3)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.0)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.3.27)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (2.2.4)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.8.2+cu101)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.2b20211201->autogluon) (2.3.2)\n",
            "Requirement already satisfied: autocfg in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.2b20211201->autogluon) (0.0.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.2b20211201->autogluon) (4.1.2.30)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.3->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.2b20211201->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.2b20211201->autogluon) (2018.9)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.2b20211201->autogluon) (36.0.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.2b20211201->autogluon) (3.2.0)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.2b20211201->autogluon) (1.4.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.2b20211201->autogluon) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.2b20211201->autogluon) (2.21)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (0.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses>=0.0.38->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1,>=1.0.0->autogluon.core==0.3.2b20211201->autogluon) (3.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (2.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.2b20211201->autogluon) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.2b20211201->autogluon) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.2b20211201->autogluon) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.2b20211201->autogluon) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.2b20211201->autogluon) (2021.10.8)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (1.0.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.2b20211201->autogluon) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.2b20211201->autogluon) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.18 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.2b20211201->autogluon) (1.23.18)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.7/dist-packages (from contextvars->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.16)\n",
            "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.6.1)\n",
            "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (2.8.0)\n",
            "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2021.09.1->autogluon.core==0.3.2b20211201->autogluon) (2.0.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.2b20211201->autogluon) (5.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.2b20211201->autogluon) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.2b20211201->autogluon) (0.11.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.2b20211201->autogluon) (0.12.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.2b20211201->autogluon) (2.5.0)\n",
            "Requirement already satisfied: minio in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.2b20211201->autogluon) (7.1.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<1.1,>=1.0->autogluon.tabular[all]==0.3.2b20211201->autogluon) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (21.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (8.12.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.2b20211201->autogluon) (0.7.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.2b20211201->autogluon) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.8.9)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.2b20211201->autogluon) (0.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTKXS9cWskfs"
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
      ],
      "id": "jTKXS9cWskfs",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0TZbXmIsdwf",
        "outputId": "2de327ee-156c-49e4-934e-6f903c336c16"
      },
      "source": [
        "# Should give the output as 1\n",
        "import torch\n",
        "import mxnet as mx\n",
        "mx.context.num_gpus()"
      ],
      "id": "B0TZbXmIsdwf",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3yhWNloty4O",
        "outputId": "bc66da46-6cb1-40b1-fe1b-4c3540bc34f2"
      },
      "source": [
        "!pip install tokenizers==0.10.1"
      ],
      "id": "f3yhWNloty4O",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers==0.10.1\n",
            "  Downloading tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.9.4\n",
            "    Uninstalling tokenizers-0.9.4:\n",
            "      Successfully uninstalled tokenizers-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autogluon-contrib-nlp 0.0.1b20210201 requires tokenizers==0.9.4, but you have tokenizers 0.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed tokenizers-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "cVgW3DUoOvEg",
        "outputId": "69a2f81d-d594-4c41-e8e5-60be355f87e3"
      },
      "source": [
        "!pip install transformers"
      ],
      "id": "cVgW3DUoOvEg",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 478 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autogluon-contrib-nlp 0.0.1b20210201 requires tokenizers==0.9.4, but you have tokenizers 0.10.1 which is incompatible.\u001b[0m\n",
            "Successfully installed huggingface-hub-0.2.0 pyyaml-6.0 transformers-4.12.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aea91b51"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "import re\n",
        "warnings.filterwarnings('ignore')"
      ],
      "id": "aea91b51",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDKEY2gQFwOD"
      },
      "source": [
        "from autogluon.core.utils import get_gpu_count, get_gpu_count_mxnet, get_gpu_count_torch, get_gpu_count_all\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import pprint\n",
        "import random\n",
        "from autogluon.tabular import TabularPredictor\n",
        "import mxnet as mx\n",
        "\n",
        "np.random.seed(123)\n",
        "random.seed(123)\n",
        "mx.random.seed(123)"
      ],
      "id": "jDKEY2gQFwOD",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVXev6zrq3jR",
        "outputId": "9ee585e6-b488-45b1-ea34-979a16278de1"
      },
      "source": [
        "# DON'T Proceed if the result is not [1, 1, 1, 1]\n",
        "print(get_gpu_count())\n",
        "print(get_gpu_count_mxnet())\n",
        "print(get_gpu_count_torch())\n",
        "print(get_gpu_count_all())"
      ],
      "id": "AVXev6zrq3jR",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbfSvc8mQuaj",
        "outputId": "8f425ca5-c1e1-41f9-d349-1662d44398e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shareddrives/CS544 Project/notebooks"
      ],
      "id": "fbfSvc8mQuaj",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shareddrives/CS544 Project/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23abf4c7"
      },
      "source": [
        "dfs = pd.read_excel(\"nlp_path_data.xlsx\")\n",
        "#dfs = dfs.rename(columns={'10000194': 'numbers', 'S19-09556': 'code', \"Invasive carcinoma of no special type (invasive ductal carcinoma, not otherwise ...\": \"descriptions\"})"
      ],
      "id": "23abf4c7",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "45de3aa1",
        "outputId": "51d04f1d-d698-46a9-ef1a-0d554f2a89bc"
      },
      "source": [
        "dfs.head()"
      ],
      "id": "45de3aa1",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Dx  Code\n",
              "0  Adenocarcinoma  8140\n",
              "1  Adenocarcinoma  8140\n",
              "2  Adenocarcinoma  8140\n",
              "3  Adenocarcinoma  8140\n",
              "4  Adenocarcinoma  8140"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8X_wKpi7BzY",
        "outputId": "1b2a7b2b-79cb-445e-95c0-dc6735904d7f"
      },
      "source": [
        "np.unique(dfs[\"Code\"])\n",
        "print(len(np.unique(dfs[\"Code\"])))"
      ],
      "id": "S8X_wKpi7BzY",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-UphtojAcga",
        "outputId": "f3512958-d0d0-421d-f04a-878ebd85beea"
      },
      "source": [
        "dfs[\"Code\"].value_counts()"
      ],
      "id": "M-UphtojAcga",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8500    1563\n",
              "8140     827\n",
              "8550     796\n",
              "8070     325\n",
              "8120     294\n",
              "        ... \n",
              "9043       1\n",
              "9231       1\n",
              "8046       1\n",
              "9680       1\n",
              "8806       1\n",
              "Name: Code, Length: 117, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwHxz8KvBdsd",
        "outputId": "d4ac25af-a244-4f19-ee55-e8e8b6c459ea"
      },
      "source": [
        "# Codes we actually want to use:\n",
        "df_grouped = dfs.groupby([\"Code\"]).count().reset_index()\n",
        "codes = df_grouped[df_grouped[\"Dx\"] > 10][\"Code\"].values\n",
        "codes"
      ],
      "id": "UwHxz8KvBdsd",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8000, 8010, 8020, 8050, 8070, 8071, 8072, 8085, 8120, 8130, 8140,\n",
              "       8144, 8150, 8170, 8230, 8240, 8250, 8252, 8260, 8310, 8312, 8317,\n",
              "       8335, 8340, 8380, 8441, 8442, 8461, 8480, 8500, 8510, 8520, 8522,\n",
              "       8550, 8575, 8720, 8721, 8742, 8743, 8744, 8745, 8802, 8850, 8858,\n",
              "       8890, 8936, 9061, 9070, 9071])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "heS1cLVRCyvA",
        "outputId": "b79edebd-1bee-4be3-d1f8-33ca2b24c770"
      },
      "source": [
        "dfs = dfs[dfs[\"Code\"].isin(codes)]\n",
        "dfs"
      ],
      "id": "heS1cLVRCyvA",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6792</th>\n",
              "      <td>Squamous Cell Carcinoma and Variants</td>\n",
              "      <td>8070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6793</th>\n",
              "      <td>Squamous cell carcinoma, conventional</td>\n",
              "      <td>8070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6794</th>\n",
              "      <td>Ductal carcinoma in situ</td>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6795</th>\n",
              "      <td>Serous carcinoma</td>\n",
              "      <td>8441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6796</th>\n",
              "      <td>Acinar adenocarcinoma</td>\n",
              "      <td>8550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6508 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Dx  Code\n",
              "0                            Adenocarcinoma  8140\n",
              "1                            Adenocarcinoma  8140\n",
              "2                            Adenocarcinoma  8140\n",
              "3                            Adenocarcinoma  8140\n",
              "4                            Adenocarcinoma  8140\n",
              "...                                     ...   ...\n",
              "6792   Squamous Cell Carcinoma and Variants  8070\n",
              "6793  Squamous cell carcinoma, conventional  8070\n",
              "6794               Ductal carcinoma in situ  8500\n",
              "6795                       Serous carcinoma  8441\n",
              "6796                  Acinar adenocarcinoma  8550\n",
              "\n",
              "[6508 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO6H4fVcFkTb",
        "outputId": "eb400e7a-9a91-4754-e64c-079d1df8b371"
      },
      "source": [
        "dfs[\"Code\"].value_counts()"
      ],
      "id": "lO6H4fVcFkTb",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8500    1563\n",
              "8140     827\n",
              "8550     796\n",
              "8070     325\n",
              "8120     294\n",
              "8312     237\n",
              "8050     213\n",
              "8743     204\n",
              "8441     184\n",
              "8380     181\n",
              "8520     174\n",
              "8000     173\n",
              "8480     118\n",
              "8130     115\n",
              "8720      96\n",
              "8010      85\n",
              "8522      71\n",
              "8936      70\n",
              "8260      66\n",
              "8150      58\n",
              "8721      47\n",
              "8240      47\n",
              "8071      46\n",
              "8744      44\n",
              "8340      38\n",
              "8850      34\n",
              "8742      31\n",
              "8170      27\n",
              "8745      26\n",
              "8072      25\n",
              "8317      24\n",
              "8461      20\n",
              "8230      19\n",
              "9061      19\n",
              "8802      18\n",
              "8575      17\n",
              "8858      16\n",
              "8250      15\n",
              "8020      15\n",
              "8252      15\n",
              "8890      14\n",
              "8442      14\n",
              "9070      13\n",
              "8085      13\n",
              "8335      13\n",
              "8310      13\n",
              "8510      12\n",
              "9071      12\n",
              "8144      11\n",
              "Name: Code, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07776dde"
      },
      "source": [
        "# Preprocessing:"
      ],
      "id": "07776dde"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQVFGs-dPzRp"
      },
      "source": [
        "#remove non-alphabetical characters, lower case, puctuation, extra spaces. \n",
        "dfs[\"Dx\"] = dfs[\"Dx\"].str.lower()\n",
        "dfs[\"Dx\"] = dfs[\"Dx\"].replace(r'[^a-z|\\s]', '', regex=True)\n",
        "dfs[\"Dx\"] = dfs[\"Dx\"].replace(r'\\s\\s+', ' ', regex=True)\n"
      ],
      "id": "DQVFGs-dPzRp",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c588e66"
      },
      "source": [
        "# BERT Embedding"
      ],
      "id": "4c588e66"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249,
          "referenced_widgets": [
            "8373e04d420a4d569e9a352549b62b85",
            "e500208583ce479ebfe97e7d2ae4db5a",
            "6d83d776c0104c449302a9f9f9017da8",
            "fdbd4eaefe91494099c4ff0220ae1e7b",
            "20c31febedef4a7b86b0ded897fcb94f",
            "3a163980a2a34ec79bf811e38284522d",
            "b8efd876360e41d7b5a815d55c25e53e",
            "fc7a3288ff59411e97151bd3ff29715c",
            "8d0d66b53261494ebdfdb3f439823e51",
            "8260c697fc1748eea7d25661b7ce36d5",
            "a8562ccb93624603bc2d5a14073c070e",
            "4d528ebece5647de8bfce2e05e2f38c6",
            "8feedfa544664d6a91adda493fd06d35",
            "5d5c6bc7950744f2be73111980b8a246",
            "fc797fa259284e41a4436aaba399765a",
            "5e8b0cdf30dd4b5290bf3d07e44f8c6c",
            "a8f47a81f3fd453fa646fb251cb1d95d",
            "f06926ad5c0e495795dc3d18bf788d02",
            "1f13d4fc13f748499cb075080c34d013",
            "d0ae33dc98e14c68912cea7d96d5fc35",
            "8b7cd935259a45c3bc736db79e16960f",
            "d0256005bb6a493492f4e5e27e9f1d23",
            "e60106f96383475db06840705ffaf274",
            "460a3f35369b41cdbcb68bc4594ee6f6",
            "70c5b427c6fa46adaf23d51e40e4e2e3",
            "bd3711e159be4bbc903ca3ac40e4a011",
            "54c454f103ac47b1bb1e70c6aa94781c",
            "ae7088576f954ffc9df7d9012c5f03cb",
            "0f463c8a66c3470e9ba8710b9c0d9c49",
            "8f856c7415d547a3b38ee664574774b0",
            "0c66934e57304a4cb44524cbd16fad1e",
            "198dc44fdff04cac82972fab58121234",
            "4b69658f10f34f9abb9bb4ab9c4e611e",
            "524a431aefcc4fb9a46ade70a6256dbf",
            "9e4d6202ff2f4270ba0515833dc23601",
            "fdc5d872832049faa614515a088b2d49",
            "d08679cbd3ec425589dd6b14741a1032",
            "5d75f8ac93014f80a23ff66c6f6e02ea",
            "e05664f187e2405baa607ead57c303a7",
            "0403cb92d8554d56bf82c51d94024586",
            "c3e7e414c1e744e2b2cece6c6aa123e1",
            "c5d2c48164e849269fb49ac551010b66",
            "5e5061f4178b4d47a871b39c3031cf72",
            "b10c04785262418c8e87021957715b59",
            "9d27e4b6390346549cffd4af745b84f4",
            "17b2d28480d44998882688f8f9900d99",
            "86c8dd834c9d42c5b18e57d5e558064e",
            "37d9fd9bff194173a9485731585b303b",
            "46ee39efb0284b80b02b0a7d6d11970d",
            "3c71984fb7074f26919612fa8bf6c9f0",
            "bd7ff25c76a34edd862444c07951f613",
            "7269938997fe4d08b9db27dce65f62d7",
            "d2ca7b1c309d46c7be014555f046db90",
            "b027c501d2e54204a246f9ca3e0780b2",
            "e77e3ba0b6a441fe9f01f65e502d3a59"
          ]
        },
        "id": "w-SQomcWQfxy",
        "outputId": "f9cbdb2c-59c9-4d4f-e446-fabbaaddc3ef"
      },
      "source": [
        "#Load the pretrained bert model\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n"
      ],
      "id": "w-SQomcWQfxy",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8373e04d420a4d569e9a352549b62b85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d528ebece5647de8bfce2e05e2f38c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e60106f96383475db06840705ffaf274",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "524a431aefcc4fb9a46ade70a6256dbf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d27e4b6390346549cffd4af745b84f4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ttEyLm0RJeE"
      },
      "source": [
        ""
      ],
      "id": "4ttEyLm0RJeE",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HUHYCAP6Tzmc",
        "outputId": "8cedd0c6-a899-458d-84c3-757c6c6c30ea"
      },
      "source": [
        "dfs"
      ],
      "id": "HUHYCAP6Tzmc",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6792</th>\n",
              "      <td>squamous cell carcinoma and variants</td>\n",
              "      <td>8070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6793</th>\n",
              "      <td>squamous cell carcinoma conventional</td>\n",
              "      <td>8070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6794</th>\n",
              "      <td>ductal carcinoma in situ</td>\n",
              "      <td>8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6795</th>\n",
              "      <td>serous carcinoma</td>\n",
              "      <td>8441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6796</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>8550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6508 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Dx  Code\n",
              "0                           adenocarcinoma  8140\n",
              "1                           adenocarcinoma  8140\n",
              "2                           adenocarcinoma  8140\n",
              "3                           adenocarcinoma  8140\n",
              "4                           adenocarcinoma  8140\n",
              "...                                    ...   ...\n",
              "6792  squamous cell carcinoma and variants  8070\n",
              "6793  squamous cell carcinoma conventional  8070\n",
              "6794              ductal carcinoma in situ  8500\n",
              "6795                      serous carcinoma  8441\n",
              "6796                 acinar adenocarcinoma  8550\n",
              "\n",
              "[6508 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igvSKaaVRvwZ",
        "outputId": "2f0f1a4b-4cdf-4016-b9d9-3be80bb5f6fd"
      },
      "source": [
        "\n",
        "#icd_codes = dfs[\"preprocessed_ICD_codes\"]\n",
        "icd_codes_d = {}\n",
        "for i, code in sorted(enumerate(set(dfs[\"Code\"]))):\n",
        "  icd_codes_d[code] = i\n",
        "icd_codes_d"
      ],
      "id": "igvSKaaVRvwZ",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{8000: 25,\n",
              " 8010: 29,\n",
              " 8020: 33,\n",
              " 8050: 42,\n",
              " 8070: 0,\n",
              " 8071: 1,\n",
              " 8072: 2,\n",
              " 8085: 9,\n",
              " 8120: 19,\n",
              " 8130: 26,\n",
              " 8140: 31,\n",
              " 8144: 32,\n",
              " 8150: 34,\n",
              " 8170: 39,\n",
              " 8230: 16,\n",
              " 8240: 17,\n",
              " 8250: 21,\n",
              " 8252: 23,\n",
              " 8260: 27,\n",
              " 8310: 43,\n",
              " 8312: 44,\n",
              " 8317: 47,\n",
              " 8335: 4,\n",
              " 8340: 8,\n",
              " 8380: 22,\n",
              " 8441: 45,\n",
              " 8442: 46,\n",
              " 8461: 3,\n",
              " 8480: 11,\n",
              " 8500: 18,\n",
              " 8510: 24,\n",
              " 8520: 28,\n",
              " 8522: 30,\n",
              " 8550: 37,\n",
              " 8575: 48,\n",
              " 8720: 5,\n",
              " 8721: 6,\n",
              " 8742: 12,\n",
              " 8743: 13,\n",
              " 8744: 14,\n",
              " 8745: 15,\n",
              " 8802: 35,\n",
              " 8850: 7,\n",
              " 8858: 10,\n",
              " 8890: 20,\n",
              " 8936: 38,\n",
              " 9061: 36,\n",
              " 9070: 40,\n",
              " 9071: 41}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdlAd_HTTAhO",
        "outputId": "859f76bc-c8bb-4e15-eb68-3fa440b3bf99"
      },
      "source": [
        "dfs['Code_n'] = dfs['Code'].apply(lambda x: icd_codes_d[x])\n",
        "dfs['Code_n']"
      ],
      "id": "JdlAd_HTTAhO",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       31\n",
              "1       31\n",
              "2       31\n",
              "3       31\n",
              "4       31\n",
              "        ..\n",
              "6792     0\n",
              "6793     0\n",
              "6794    18\n",
              "6795    45\n",
              "6796    37\n",
              "Name: Code_n, Length: 6508, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vfoqDQHESlPx",
        "outputId": "429879a3-6c6e-4f00-f6ce-a597392b8e96"
      },
      "source": [
        "dfs"
      ],
      "id": "vfoqDQHESlPx",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code</th>\n",
              "      <th>Code_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6792</th>\n",
              "      <td>squamous cell carcinoma and variants</td>\n",
              "      <td>8070</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6793</th>\n",
              "      <td>squamous cell carcinoma conventional</td>\n",
              "      <td>8070</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6794</th>\n",
              "      <td>ductal carcinoma in situ</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6795</th>\n",
              "      <td>serous carcinoma</td>\n",
              "      <td>8441</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6796</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>8550</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6508 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Dx  Code  Code_n\n",
              "0                           adenocarcinoma  8140      31\n",
              "1                           adenocarcinoma  8140      31\n",
              "2                           adenocarcinoma  8140      31\n",
              "3                           adenocarcinoma  8140      31\n",
              "4                           adenocarcinoma  8140      31\n",
              "...                                    ...   ...     ...\n",
              "6792  squamous cell carcinoma and variants  8070       0\n",
              "6793  squamous cell carcinoma conventional  8070       0\n",
              "6794              ductal carcinoma in situ  8500      18\n",
              "6795                      serous carcinoma  8441      45\n",
              "6796                 acinar adenocarcinoma  8550      37\n",
              "\n",
              "[6508 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWLhwU_DUJ80"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(dfs, test_size=0.2)"
      ],
      "id": "XWLhwU_DUJ80",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5I3-aj74UdDl",
        "outputId": "14cb93bc-8809-4cf0-f793-c67ca1a39c15"
      },
      "source": [
        "train = train.reset_index(drop = True)\n",
        "train"
      ],
      "id": "5I3-aj74UdDl",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code</th>\n",
              "      <th>Code_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>8550</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>papillary urothelial carcinoma noninvasive</td>\n",
              "      <td>8130</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>papillary carcinoma other variant specify</td>\n",
              "      <td>8260</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>papillary urothelial carcinoma invasive</td>\n",
              "      <td>8130</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>invasive lobular carcinoma</td>\n",
              "      <td>8520</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5201</th>\n",
              "      <td>endometrioid carcinoma nos</td>\n",
              "      <td>8380</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5202</th>\n",
              "      <td>serous carcinoma</td>\n",
              "      <td>8441</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5203</th>\n",
              "      <td>invasive lobular carcinoma</td>\n",
              "      <td>8520</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5204</th>\n",
              "      <td>diffuse type includes signetring carcinoma cla...</td>\n",
              "      <td>8010</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>serous carcinoma</td>\n",
              "      <td>8441</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5206 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Dx  Code  Code_n\n",
              "0                                 acinar adenocarcinoma  8550      37\n",
              "1            papillary urothelial carcinoma noninvasive  8130      26\n",
              "2             papillary carcinoma other variant specify  8260      27\n",
              "3               papillary urothelial carcinoma invasive  8130      26\n",
              "4                            invasive lobular carcinoma  8520      28\n",
              "...                                                 ...   ...     ...\n",
              "5201                         endometrioid carcinoma nos  8380      22\n",
              "5202                                   serous carcinoma  8441      45\n",
              "5203                         invasive lobular carcinoma  8520      28\n",
              "5204  diffuse type includes signetring carcinoma cla...  8010      29\n",
              "5205                                   serous carcinoma  8441      45\n",
              "\n",
              "[5206 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sGLxRH9IUfmT",
        "outputId": "9cb80897-94a0-43c4-f72f-2f77e942a01c"
      },
      "source": [
        "test = test.reset_index(drop = True)\n",
        "test"
      ],
      "id": "sGLxRH9IUfmT",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code</th>\n",
              "      <th>Code_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>8550</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>8550</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>8550</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>invasive carcinoma of no special type invasive...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1297</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>8140</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299</th>\n",
              "      <td>papillary carcinoma follicular variant encapsu...</td>\n",
              "      <td>8340</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1300</th>\n",
              "      <td>invasive mucinous adenocarcinoma</td>\n",
              "      <td>8252</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1301</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>8550</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1302 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Dx  Code  Code_n\n",
              "0                                 acinar adenocarcinoma  8550      37\n",
              "1                                 acinar adenocarcinoma  8550      37\n",
              "2                                 acinar adenocarcinoma  8550      37\n",
              "3     invasive carcinoma of no special type ductal n...  8500      18\n",
              "4     invasive carcinoma of no special type invasive...  8500      18\n",
              "...                                                 ...   ...     ...\n",
              "1297  invasive carcinoma of no special type ductal n...  8500      18\n",
              "1298                                     adenocarcinoma  8140      31\n",
              "1299  papillary carcinoma follicular variant encapsu...  8340       8\n",
              "1300                   invasive mucinous adenocarcinoma  8252      23\n",
              "1301                              acinar adenocarcinoma  8550      37\n",
              "\n",
              "[1302 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__Ow89cHVoQp",
        "outputId": "74936b49-0687-4bb2-ff0b-8cc0b3ccf78b"
      },
      "source": [
        "#pad everything to the same size! Set to the length of the largest input\n",
        "tokenized = test[\"Dx\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "print(tokenized[0])\n",
        "# Set manually \n",
        "max_len = 34\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "#implement the attention mask\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "print(attention_mask[0])\n",
        "test_attention_mask = attention_mask\n",
        "input_ids = torch.tensor(padded)\n",
        "index = 1\n",
        "print(input_ids[index])\n",
        "print(test[\"Dx\"][index])"
      ],
      "id": "__Ow89cHVoQp",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 9353, 3981, 2099, 16298, 24755, 11890, 5740, 2863, 102]\n",
            "[1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "tensor([  101,  9353,  3981,  2099, 16298, 24755, 11890,  5740,  2863,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "acinar adenocarcinoma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kgZ1pDsjKDYn",
        "outputId": "d9267d78-5e61-459e-b8ef-c10cd00fe175"
      },
      "source": [
        "test_df = pd.DataFrame(columns = ['Dx', 'Code_n'])\n",
        "test_df['Dx'] = test['Dx'].values.tolist()\n",
        "test_df['Code_n'] = test['Code_n'].values.tolist()\n",
        "test_df"
      ],
      "id": "kgZ1pDsjKDYn",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>invasive carcinoma of no special type invasive...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1297</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>adenocarcinoma</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299</th>\n",
              "      <td>papillary carcinoma follicular variant encapsu...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1300</th>\n",
              "      <td>invasive mucinous adenocarcinoma</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1301</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1302 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Dx  Code_n\n",
              "0                                 acinar adenocarcinoma      37\n",
              "1                                 acinar adenocarcinoma      37\n",
              "2                                 acinar adenocarcinoma      37\n",
              "3     invasive carcinoma of no special type ductal n...      18\n",
              "4     invasive carcinoma of no special type invasive...      18\n",
              "...                                                 ...     ...\n",
              "1297  invasive carcinoma of no special type ductal n...      18\n",
              "1298                                     adenocarcinoma      31\n",
              "1299  papillary carcinoma follicular variant encapsu...       8\n",
              "1300                   invasive mucinous adenocarcinoma      23\n",
              "1301                              acinar adenocarcinoma      37\n",
              "\n",
              "[1302 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUDVk7VDyX97"
      },
      "source": [
        "test_df_cp = test_df.copy()\n",
        "test_inputs = torch.tensor(input_ids)"
      ],
      "id": "eUDVk7VDyX97",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAYyKG_eoOew",
        "outputId": "83e58710-7484-4375-af8b-7577c06bfb4b"
      },
      "source": [
        "test_df.shape"
      ],
      "id": "SAYyKG_eoOew",
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1302, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rskJ6JOiWRaI",
        "outputId": "1ac9d3da-b6f0-44a4-8e35-d3a9b93ff371"
      },
      "source": [
        "x_test = input_ids\n",
        "attention_mask_test = attention_mask\n",
        "y_test = test['Code_n'].values\n",
        "x_test.shape, y_test.shape"
      ],
      "id": "rskJ6JOiWRaI",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1302, 34]), (1302,))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFd6eSXQYhyH"
      },
      "source": [
        "test_data = []\n",
        "for i in range(len(x_test)):\n",
        "    test_data.append([attention_mask_test[i], x_test[i], y_test[i]])"
      ],
      "id": "mFd6eSXQYhyH",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYJF9EthUhNx"
      },
      "source": [
        "dfs = train"
      ],
      "id": "GYJF9EthUhNx",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTojYE8AUK9E"
      },
      "source": [
        "## Upsampling"
      ],
      "id": "XTojYE8AUK9E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ5fUkWIZkh_",
        "outputId": "1d5d9c0d-af9b-40eb-a6fc-c6dc65f07a5a"
      },
      "source": [
        "dfs['Code'].value_counts()"
      ],
      "id": "EQ5fUkWIZkh_",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8500    1268\n",
              "8140     669\n",
              "8550     636\n",
              "8070     264\n",
              "8120     235\n",
              "8312     189\n",
              "8050     176\n",
              "8743     153\n",
              "8441     153\n",
              "8380     146\n",
              "8520     137\n",
              "8000     132\n",
              "8480     100\n",
              "8130      90\n",
              "8720      76\n",
              "8010      62\n",
              "8936      61\n",
              "8522      51\n",
              "8260      48\n",
              "8150      44\n",
              "8240      41\n",
              "8721      39\n",
              "8071      34\n",
              "8744      32\n",
              "8850      31\n",
              "8340      29\n",
              "8742      27\n",
              "8170      24\n",
              "8745      22\n",
              "8317      22\n",
              "8230      16\n",
              "8461      16\n",
              "8072      16\n",
              "8575      15\n",
              "9061      14\n",
              "8802      12\n",
              "8252      12\n",
              "8858      12\n",
              "8890      11\n",
              "8085      11\n",
              "8250      10\n",
              "8310      10\n",
              "8335       9\n",
              "8510       9\n",
              "8020       9\n",
              "8144       9\n",
              "9070       8\n",
              "9071       8\n",
              "8442       8\n",
              "Name: Code, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GU_A55VvEBXR",
        "outputId": "fc925e30-1d93-4ca9-dc9a-d359e4927400"
      },
      "source": [
        "### Upsample for Class balance:\n",
        "from sklearn.utils import resample\n",
        "\n",
        "df_majority = dfs[dfs.loc[:,\"Code\"]==8500]\n",
        "max_len = len(df_majority)\n",
        "for code in codes:\n",
        "  if code != 8500:\n",
        "    df_minority = dfs[dfs.loc[:,\"Code\"]==code]\n",
        "    upsampled_minority = resample(df_minority, replace=True, n_samples=max_len)\n",
        "    df_majority = pd.concat([df_majority, upsampled_minority])\n",
        "\n",
        "df_majority"
      ],
      "id": "GU_A55VvEBXR",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code</th>\n",
              "      <th>Code_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>invasive carcinoma of no special type ductal</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ductal carcinoma in situ</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>yolk sac tumor postpubertal type specify perce...</td>\n",
              "      <td>9071</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4864</th>\n",
              "      <td>yolk sac tumor endodermal sinus tumor</td>\n",
              "      <td>9071</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2645</th>\n",
              "      <td>yolk sac tumor postpubertal type specify perce...</td>\n",
              "      <td>9071</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>672</th>\n",
              "      <td>yolk sac tumor postpubertal type specify perce...</td>\n",
              "      <td>9071</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4864</th>\n",
              "      <td>yolk sac tumor endodermal sinus tumor</td>\n",
              "      <td>9071</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>62132 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Dx  Code  Code_n\n",
              "5          invasive carcinoma of no special type ductal  8500      18\n",
              "7     invasive carcinoma of no special type ductal n...  8500      18\n",
              "8     invasive carcinoma of no special type ductal n...  8500      18\n",
              "11                             ductal carcinoma in situ  8500      18\n",
              "13    invasive carcinoma of no special type ductal n...  8500      18\n",
              "...                                                 ...   ...     ...\n",
              "1024  yolk sac tumor postpubertal type specify perce...  9071      41\n",
              "4864              yolk sac tumor endodermal sinus tumor  9071      41\n",
              "2645  yolk sac tumor postpubertal type specify perce...  9071      41\n",
              "672   yolk sac tumor postpubertal type specify perce...  9071      41\n",
              "4864              yolk sac tumor endodermal sinus tumor  9071      41\n",
              "\n",
              "[62132 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZi5L0g9FXap",
        "outputId": "ed90714d-2904-414a-dbd9-870247d64d25"
      },
      "source": [
        "#Proof of upsample working:\n",
        "df_majority[\"Code\"].value_counts()[1:10]"
      ],
      "id": "qZi5L0g9FXap",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8522    1268\n",
              "8936    1268\n",
              "8744    1268\n",
              "8520    1268\n",
              "8072    1268\n",
              "9071    1268\n",
              "8335    1268\n",
              "9070    1268\n",
              "8170    1268\n",
              "Name: Code, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6lDYMmPATsy"
      },
      "source": [
        "### How many Codes do we want??? 1) 117 2) grouped version"
      ],
      "id": "Z6lDYMmPATsy",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb60aC85GGTm"
      },
      "source": [
        "df_upsampled = df_majority.copy()"
      ],
      "id": "Jb60aC85GGTm",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bWBBg1qRG4D9",
        "outputId": "c72c4b64-3b57-4d50-9d01-630368cbfaa4"
      },
      "source": [
        "'''\n",
        "#remove non-alphabetical characters, lower case, puctuation, extra spaces. \n",
        "df_upsampled[\"Dx\"] = df_upsampled[\"Dx\"].str.lower()\n",
        "df_upsampled[\"Dx\"] = df_upsampled[\"Dx\"].replace(r'[^a-z|\\s]', '', regex=True)\n",
        "df_upsampled[\"Dx\"] = df_upsampled[\"Dx\"].replace(r'\\s\\s+', ' ', regex=True)\n",
        "'''"
      ],
      "id": "bWBBg1qRG4D9",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#remove non-alphabetical characters, lower case, puctuation, extra spaces. \\ndf_upsampled[\"Dx\"] = df_upsampled[\"Dx\"].str.lower()\\ndf_upsampled[\"Dx\"] = df_upsampled[\"Dx\"].replace(r\\'[^a-z|\\\\s]\\', \\'\\', regex=True)\\ndf_upsampled[\"Dx\"] = df_upsampled[\"Dx\"].replace(r\\'\\\\s\\\\s+\\', \\' \\', regex=True)\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E5ZnenoHXIy",
        "outputId": "8c24e534-f15b-4d96-c79a-033447ffefce"
      },
      "source": [
        "df_upsampled[\"Dx\"]"
      ],
      "id": "3E5ZnenoHXIy",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5            invasive carcinoma of no special type ductal\n",
              "7       invasive carcinoma of no special type ductal n...\n",
              "8       invasive carcinoma of no special type ductal n...\n",
              "11                               ductal carcinoma in situ\n",
              "13      invasive carcinoma of no special type ductal n...\n",
              "                              ...                        \n",
              "1024    yolk sac tumor postpubertal type specify perce...\n",
              "4864                yolk sac tumor endodermal sinus tumor\n",
              "2645    yolk sac tumor postpubertal type specify perce...\n",
              "672     yolk sac tumor postpubertal type specify perce...\n",
              "4864                yolk sac tumor endodermal sinus tumor\n",
              "Name: Dx, Length: 62132, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ah93XTTQH8la",
        "outputId": "a7597805-a81e-4248-b40b-c98c8031c71e"
      },
      "source": [
        "df_upsampled.head()"
      ],
      "id": "Ah93XTTQH8la",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code</th>\n",
              "      <th>Code_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>invasive carcinoma of no special type ductal</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ductal carcinoma in situ</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>invasive carcinoma of no special type ductal n...</td>\n",
              "      <td>8500</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Dx  Code  Code_n\n",
              "5        invasive carcinoma of no special type ductal  8500      18\n",
              "7   invasive carcinoma of no special type ductal n...  8500      18\n",
              "8   invasive carcinoma of no special type ductal n...  8500      18\n",
              "11                           ductal carcinoma in situ  8500      18\n",
              "13  invasive carcinoma of no special type ductal n...  8500      18"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "MQbMp0WgZ-D-",
        "outputId": "a0816468-5b13-4ed3-d2b0-57d3d4746b66"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(10,6))\n",
        "df_upsampled['Code'].value_counts().plot(ax=ax, kind='bar')\n",
        "ax.set_xlabel(\"ICD_Code\")\n",
        "ax.set_ylabel(\"Value Counts\")\n",
        "ax.set_title(\"Value Counts Across ICD Codes\");"
      ],
      "id": "MQbMp0WgZ-D-",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ce6332f8",
        "outputId": "5a7c2f5a-3374-4fb4-c5a5-9cd7f76d15a9"
      },
      "source": [
        "'''\n",
        "#Load the pretrained bert model\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
        "\n",
        "# Load pretrained model/tokenizer\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)\n",
        "'''"
      ],
      "id": "ce6332f8",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#Load the pretrained bert model\\nmodel_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\\n\\n# Load pretrained model/tokenizer\\ntokenizer = tokenizer_class.from_pretrained(pretrained_weights)\\nmodel = model_class.from_pretrained(pretrained_weights)\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOiisxiA-5Rn",
        "outputId": "e14b2d02-b274-4c55-ef77-6abd470d51e1"
      },
      "source": [
        "from transformers import AutoModel\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')"
      ],
      "id": "dOiisxiA-5Rn",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6UlA-rBUeXh"
      },
      "source": [
        "#df_upsampled.iloc[1392]"
      ],
      "id": "-6UlA-rBUeXh",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ae72936"
      },
      "source": [
        "tokenized = df_upsampled[\"Dx\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "id": "5ae72936",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxtwWtreWSFe",
        "outputId": "bfe7e897-19a0-4415-b6b7-25422aa8047e"
      },
      "source": [
        "tokenized.iloc[1392]"
      ],
      "id": "BxtwWtreWSFe",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 13866,\n",
              " 13656,\n",
              " 2062,\n",
              " 2084,\n",
              " 4642,\n",
              " 1998,\n",
              " 2625,\n",
              " 2084,\n",
              " 2030,\n",
              " 5020,\n",
              " 2000,\n",
              " 4642,\n",
              " 1999,\n",
              " 4602,\n",
              " 9812,\n",
              " 102]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25e953e5"
      },
      "source": [
        "#pad everything to the same size! Set to the length of the largest input\n",
        "max_len = 34\n",
        "'''\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "'''\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "id": "25e953e5",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c62616b",
        "outputId": "264b8610-5836-40e4-c707-c798195a5aad"
      },
      "source": [
        "#implement the attention mask\n",
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ],
      "id": "6c62616b",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(62132, 34)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77cb29eb"
      },
      "source": [
        "input_ids = torch.tensor(padded)"
      ],
      "id": "77cb29eb",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b84b6dc9",
        "outputId": "0eefd877-4e48-41d5-d2e9-e1cfaf108c03"
      },
      "source": [
        "#input_ids is the embedding of the sentence\n",
        "print(len(input_ids))\n",
        "print(len(df_upsampled))"
      ],
      "id": "b84b6dc9",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62132\n",
            "62132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "535b9f1d",
        "outputId": "519e9885-56b3-41f8-fc69-6ebcc159fd37"
      },
      "source": [
        "index = 1\n",
        "print(input_ids[index])\n",
        "print(df_upsampled[\"Dx\"][index])"
      ],
      "id": "535b9f1d",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  101, 17503,  2482, 21081,  2863,  1997,  2053,  2569,  2828, 23245,\n",
            "         2389,  2025,  4728,  9675,   102,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "1    papillary urothelial carcinoma noninvasive\n",
            "Name: Dx, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jk4y5nwZb9f"
      },
      "source": [
        "### Have to encode 0-9 each of the ICD Codes: "
      ],
      "id": "4Jk4y5nwZb9f",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR2LTXq7ae06",
        "outputId": "9460cc02-2676-4e9a-f063-e079e745a2f8"
      },
      "source": [
        "#vectorize the Y keys to corresponding values:\n",
        "y_train = df_upsampled[\"Code\"].values\n",
        "y_train = np.vectorize(icd_codes_d.get)(y_train)\n",
        "y_train"
      ],
      "id": "nR2LTXq7ae06",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([18, 18, 18, ..., 41, 41, 41])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzgQN-W9Mu-y"
      },
      "source": [
        "# train, dev, test: "
      ],
      "id": "nzgQN-W9Mu-y",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJGpElFYLda7"
      },
      "source": [
        "total_vals = df_upsampled['Dx'].values"
      ],
      "id": "eJGpElFYLda7",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShtHyoCSMZIF",
        "outputId": "9b123861-51f8-485a-a170-41d0a3dead65"
      },
      "source": [
        "input_ids.shape, total_vals.shape"
      ],
      "id": "ShtHyoCSMZIF",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([62132, 34]), (62132,))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4lagiQCblrf",
        "outputId": "354b89bc-8525-4547-c014-fde08222d46a"
      },
      "source": [
        "# train-test split:\n",
        "test_size = int(np.floor(len(y_train)*.25))\n",
        "rand_test_ints = np.random.randint(low=0, high=len(y_train), size=test_size)\n",
        "print(y_train.shape)\n",
        "y_dev = y_train[rand_test_ints]\n",
        "y_train = np.delete(y_train, rand_test_ints, axis=0)\n",
        "\n",
        "x_dev = total_vals[rand_test_ints]\n",
        "print(x_dev.shape, total_vals.shape)\n",
        "x_train = np.delete(total_vals, rand_test_ints, axis=0)\n",
        "print(x_train.shape)\n",
        "x_train_k = np.delete(input_ids, rand_test_ints, axis=0) \n",
        "print(x_train_k.shape)\n",
        "attention_mask_dev = attention_mask[rand_test_ints]\n",
        "attention_mask_train = np.delete(attention_mask, rand_test_ints, axis = 0)"
      ],
      "id": "Q4lagiQCblrf",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(62132,)\n",
            "(15533,) (62132,)\n",
            "(48408,)\n",
            "torch.Size([48408, 34])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB8bnOcgMBQh",
        "outputId": "28af6322-cf47-4ed4-9577-4d0856b7d20d"
      },
      "source": [
        "y_train.shape, x_train.shape"
      ],
      "id": "vB8bnOcgMBQh",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((48408,), (48408,))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI2wPaGRH-Dg",
        "outputId": "7966a531-4cba-40a5-eac1-837add9c6cc9"
      },
      "source": [
        "subsample_size = 2000  # for quick demo, try setting to larger values\n",
        "feature_columns = ['Dx']\n",
        "label = 'Code_n'\n",
        "\n",
        "train_df = pd.DataFrame(x_train, columns = ['Dx'])\n",
        "train_df['Code_n'] = y_train\n",
        "dev_df = pd.DataFrame(x_dev, columns = ['Dx'])\n",
        "dev_df['Code_n'] = y_dev\n",
        "\n",
        "train_df = train_df[feature_columns + [label]]\n",
        "dev_df = dev_df[feature_columns + [label]]\n",
        "test_df = test_df[feature_columns]\n",
        "print('Number of training samples:', len(train_df))\n",
        "print('Number of dev samples:', len(dev_df))\n",
        "print('Number of test samples:', len(test_df))"
      ],
      "id": "CI2wPaGRH-Dg",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 48408\n",
            "Number of dev samples: 15533\n",
            "Number of test samples: 1302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "i3HMQxv4Mh-u",
        "outputId": "d2fc0909-f9cd-4a43-fb7f-3325c58bf01f"
      },
      "source": [
        "dev_df.head()"
      ],
      "id": "i3HMQxv4Mh-u",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dx</th>\n",
              "      <th>Code_n</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>invasive adenocarcinoma solid predominant</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acinar adenocarcinoma</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>acrallentiginous melanoma</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mucinous carcinoma</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>undifferentiated pleomorphic sarcoma</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Dx  Code_n\n",
              "0  invasive adenocarcinoma solid predominant      16\n",
              "1                      acinar adenocarcinoma      37\n",
              "2                  acrallentiginous melanoma      14\n",
              "3                         mucinous carcinoma      11\n",
              "4       undifferentiated pleomorphic sarcoma      35"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rPaNn7yvYe7",
        "outputId": "c121a2c9-5f61-40ff-f785-e4b5015fae44"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "model_1 = LGBMClassifier(boosting_type='gbdt', learning_rate= 0.05, num_boost_round=7,num_threads= -1, objective='multiclass',\n",
        " two_round= True, verbose= -1)\n",
        "model_1.fit(x_train_k, train_df['Code_n'])"
      ],
      "id": "5rPaNn7yvYe7",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(learning_rate=0.05, num_boost_round=7, num_threads=-1,\n",
              "               objective='multiclass', two_round=True, verbose=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeB000A9xSBL"
      },
      "source": [
        "predicted_vals = model_1.predict(test_inputs)"
      ],
      "id": "FeB000A9xSBL",
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXEarSLky4zh",
        "outputId": "4297da1d-4bdc-4956-fc83-3fa544dd74ba"
      },
      "source": [
        "from sklearn.metrics import classification_report, average_precision_score\n",
        "print(classification_report(test_df['Code_n'], predicted_vals))"
      ],
      "id": "mXEarSLky4zh",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        61\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       0.90      1.00      0.95         9\n",
            "           3       1.00      1.00      1.00         4\n",
            "           4       1.00      1.00      1.00         4\n",
            "           5       0.95      0.95      0.95        20\n",
            "           6       1.00      0.88      0.93         8\n",
            "           7       1.00      1.00      1.00         3\n",
            "           8       1.00      1.00      1.00         9\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         4\n",
            "          11       0.95      1.00      0.97        18\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      1.00      1.00        51\n",
            "          14       1.00      1.00      1.00        12\n",
            "          15       1.00      1.00      1.00         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       0.80      0.67      0.73         6\n",
            "          18       0.99      1.00      0.99       295\n",
            "          19       1.00      1.00      1.00        59\n",
            "          20       1.00      1.00      1.00         3\n",
            "          21       1.00      1.00      1.00         5\n",
            "          22       1.00      1.00      1.00        35\n",
            "          23       1.00      1.00      1.00         3\n",
            "          24       0.67      0.67      0.67         3\n",
            "          25       1.00      0.90      0.95        41\n",
            "          26       1.00      1.00      1.00        25\n",
            "          27       1.00      1.00      1.00        18\n",
            "          28       1.00      0.97      0.99        37\n",
            "          29       0.96      0.96      0.96        23\n",
            "          30       1.00      1.00      1.00        20\n",
            "          31       1.00      0.99      0.99       158\n",
            "          32       1.00      1.00      1.00         2\n",
            "          33       1.00      0.67      0.80         6\n",
            "          34       0.88      1.00      0.93        14\n",
            "          35       1.00      1.00      1.00         6\n",
            "          36       1.00      1.00      1.00         5\n",
            "          37       1.00      1.00      1.00       160\n",
            "          38       1.00      1.00      1.00         9\n",
            "          39       0.75      1.00      0.86         3\n",
            "          40       1.00      0.80      0.89         5\n",
            "          41       1.00      0.75      0.86         4\n",
            "          42       1.00      0.97      0.99        37\n",
            "          43       1.00      1.00      1.00         3\n",
            "          44       0.94      0.98      0.96        48\n",
            "          45       1.00      1.00      1.00        31\n",
            "          46       0.86      1.00      0.92         6\n",
            "          47       1.00      1.00      1.00         2\n",
            "          48       0.40      1.00      0.57         2\n",
            "\n",
            "    accuracy                           0.98      1302\n",
            "   macro avg       0.96      0.96      0.96      1302\n",
            "weighted avg       0.99      0.98      0.98      1302\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9MVmf-I1ebI",
        "outputId": "fa2ee905-20d7-49a4-a618-75f47a5c1de9"
      },
      "source": [
        "!pip install catboost"
      ],
      "id": "a9MVmf-I1ebI",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.6.3)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.8.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.6)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPZD6Nr1hKh",
        "outputId": "b332014a-0d4d-4fee-9cf8-52875a695323"
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "model_2 = CatBoostClassifier(\n",
        "allow_writing_files =  False,\n",
        " eval_metric =  'Accuracy',\n",
        " iterations =  154,\n",
        " learning_rate = 0.05,\n",
        " random_seed = 0\n",
        ")\n",
        "\n",
        "\n",
        "model_2.fit(np.array(x_train_k), train_df['Code_n'],  verbose=True\n",
        ")"
      ],
      "id": "oqPZD6Nr1hKh",
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.5045654\ttotal: 1.13s\tremaining: 2m 53s\n",
            "1:\tlearn: 0.5894893\ttotal: 2.3s\tremaining: 2m 54s\n",
            "2:\tlearn: 0.6749504\ttotal: 3.44s\tremaining: 2m 53s\n",
            "3:\tlearn: 0.8590729\ttotal: 4.57s\tremaining: 2m 51s\n",
            "4:\tlearn: 0.8853289\ttotal: 5.7s\tremaining: 2m 49s\n",
            "5:\tlearn: 0.9070402\ttotal: 6.84s\tremaining: 2m 48s\n",
            "6:\tlearn: 0.9070402\ttotal: 7.98s\tremaining: 2m 47s\n",
            "7:\tlearn: 0.9138572\ttotal: 9.12s\tremaining: 2m 46s\n",
            "8:\tlearn: 0.9453603\ttotal: 10.2s\tremaining: 2m 45s\n",
            "9:\tlearn: 0.9560197\ttotal: 11.4s\tremaining: 2m 43s\n",
            "10:\tlearn: 0.9568253\ttotal: 12.5s\tremaining: 2m 42s\n",
            "11:\tlearn: 0.9627128\ttotal: 13.7s\tremaining: 2m 41s\n",
            "12:\tlearn: 0.9635804\ttotal: 14.8s\tremaining: 2m 40s\n",
            "13:\tlearn: 0.9635804\ttotal: 15.9s\tremaining: 2m 39s\n",
            "14:\tlearn: 0.9672781\ttotal: 17.1s\tremaining: 2m 38s\n",
            "15:\tlearn: 0.9672781\ttotal: 18.2s\tremaining: 2m 37s\n",
            "16:\tlearn: 0.9737027\ttotal: 19.4s\tremaining: 2m 35s\n",
            "17:\tlearn: 0.9710585\ttotal: 20.5s\tremaining: 2m 34s\n",
            "18:\tlearn: 0.9801892\ttotal: 21.6s\tremaining: 2m 33s\n",
            "19:\tlearn: 0.9801892\ttotal: 22.8s\tremaining: 2m 32s\n",
            "20:\tlearn: 0.9846926\ttotal: 24s\tremaining: 2m 31s\n",
            "21:\tlearn: 0.9849198\ttotal: 25.1s\tremaining: 2m 30s\n",
            "22:\tlearn: 0.9849198\ttotal: 26.3s\tremaining: 2m 29s\n",
            "23:\tlearn: 0.9842175\ttotal: 27.4s\tremaining: 2m 28s\n",
            "24:\tlearn: 0.9843414\ttotal: 28.5s\tremaining: 2m 27s\n",
            "25:\tlearn: 0.9854156\ttotal: 29.7s\tremaining: 2m 26s\n",
            "26:\tlearn: 0.9856429\ttotal: 30.8s\tremaining: 2m 24s\n",
            "27:\tlearn: 0.9845687\ttotal: 32s\tremaining: 2m 23s\n",
            "28:\tlearn: 0.9856429\ttotal: 33.1s\tremaining: 2m 22s\n",
            "29:\tlearn: 0.9856429\ttotal: 34.3s\tremaining: 2m 21s\n",
            "30:\tlearn: 0.9876467\ttotal: 35.4s\tremaining: 2m 20s\n",
            "31:\tlearn: 0.9878326\ttotal: 36.6s\tremaining: 2m 19s\n",
            "32:\tlearn: 0.9877293\ttotal: 37.7s\tremaining: 2m 18s\n",
            "33:\tlearn: 0.9880185\ttotal: 38.9s\tremaining: 2m 17s\n",
            "34:\tlearn: 0.9885143\ttotal: 40s\tremaining: 2m 16s\n",
            "35:\tlearn: 0.9885143\ttotal: 41.2s\tremaining: 2m 14s\n",
            "36:\tlearn: 0.9885143\ttotal: 42.3s\tremaining: 2m 13s\n",
            "37:\tlearn: 0.9885143\ttotal: 43.4s\tremaining: 2m 12s\n",
            "38:\tlearn: 0.9885143\ttotal: 44.6s\tremaining: 2m 11s\n",
            "39:\tlearn: 0.9886796\ttotal: 45.7s\tremaining: 2m 10s\n",
            "40:\tlearn: 0.9889688\ttotal: 46.9s\tremaining: 2m 9s\n",
            "41:\tlearn: 0.9893613\ttotal: 48s\tremaining: 2m 7s\n",
            "42:\tlearn: 0.9905388\ttotal: 49.1s\tremaining: 2m 6s\n",
            "43:\tlearn: 0.9904561\ttotal: 50.3s\tremaining: 2m 5s\n",
            "44:\tlearn: 0.9916336\ttotal: 51.4s\tremaining: 2m 4s\n",
            "45:\tlearn: 0.9919848\ttotal: 52.6s\tremaining: 2m 3s\n",
            "46:\tlearn: 0.9922327\ttotal: 53.7s\tremaining: 2m 2s\n",
            "47:\tlearn: 0.9922327\ttotal: 54.9s\tremaining: 2m 1s\n",
            "48:\tlearn: 0.9946496\ttotal: 56s\tremaining: 2m\n",
            "49:\tlearn: 0.9946496\ttotal: 57.2s\tremaining: 1m 58s\n",
            "50:\tlearn: 0.9947736\ttotal: 58.3s\tremaining: 1m 57s\n",
            "51:\tlearn: 0.9953314\ttotal: 59.5s\tremaining: 1m 56s\n",
            "52:\tlearn: 0.9954966\ttotal: 1m\tremaining: 1m 55s\n",
            "53:\tlearn: 0.9957032\ttotal: 1m 1s\tremaining: 1m 54s\n",
            "54:\tlearn: 0.9959924\ttotal: 1m 2s\tremaining: 1m 53s\n",
            "55:\tlearn: 0.9959924\ttotal: 1m 4s\tremaining: 1m 52s\n",
            "56:\tlearn: 0.9960131\ttotal: 1m 5s\tremaining: 1m 50s\n",
            "57:\tlearn: 0.9962196\ttotal: 1m 6s\tremaining: 1m 49s\n",
            "58:\tlearn: 0.9962196\ttotal: 1m 7s\tremaining: 1m 48s\n",
            "59:\tlearn: 0.9962196\ttotal: 1m 8s\tremaining: 1m 47s\n",
            "60:\tlearn: 0.9962196\ttotal: 1m 9s\tremaining: 1m 46s\n",
            "61:\tlearn: 0.9963642\ttotal: 1m 10s\tremaining: 1m 45s\n",
            "62:\tlearn: 0.9966534\ttotal: 1m 11s\tremaining: 1m 43s\n",
            "63:\tlearn: 0.9966534\ttotal: 1m 13s\tremaining: 1m 42s\n",
            "64:\tlearn: 0.9968600\ttotal: 1m 14s\tremaining: 1m 41s\n",
            "65:\tlearn: 0.9968600\ttotal: 1m 15s\tremaining: 1m 40s\n",
            "66:\tlearn: 0.9968600\ttotal: 1m 16s\tremaining: 1m 39s\n",
            "67:\tlearn: 0.9968600\ttotal: 1m 17s\tremaining: 1m 38s\n",
            "68:\tlearn: 0.9970046\ttotal: 1m 18s\tremaining: 1m 36s\n",
            "69:\tlearn: 0.9974591\ttotal: 1m 19s\tremaining: 1m 35s\n",
            "70:\tlearn: 0.9975830\ttotal: 1m 20s\tremaining: 1m 34s\n",
            "71:\tlearn: 0.9977070\ttotal: 1m 22s\tremaining: 1m 33s\n",
            "72:\tlearn: 0.9977070\ttotal: 1m 23s\tremaining: 1m 32s\n",
            "73:\tlearn: 0.9977070\ttotal: 1m 24s\tremaining: 1m 31s\n",
            "74:\tlearn: 0.9977070\ttotal: 1m 25s\tremaining: 1m 29s\n",
            "75:\tlearn: 0.9977896\ttotal: 1m 26s\tremaining: 1m 28s\n",
            "76:\tlearn: 0.9977896\ttotal: 1m 27s\tremaining: 1m 27s\n",
            "77:\tlearn: 0.9977896\ttotal: 1m 28s\tremaining: 1m 26s\n",
            "78:\tlearn: 0.9977896\ttotal: 1m 29s\tremaining: 1m 25s\n",
            "79:\tlearn: 0.9977896\ttotal: 1m 31s\tremaining: 1m 24s\n",
            "80:\tlearn: 0.9977896\ttotal: 1m 32s\tremaining: 1m 23s\n",
            "81:\tlearn: 0.9977896\ttotal: 1m 33s\tremaining: 1m 21s\n",
            "82:\tlearn: 0.9977896\ttotal: 1m 34s\tremaining: 1m 20s\n",
            "83:\tlearn: 0.9977896\ttotal: 1m 35s\tremaining: 1m 19s\n",
            "84:\tlearn: 0.9977896\ttotal: 1m 36s\tremaining: 1m 18s\n",
            "85:\tlearn: 0.9977896\ttotal: 1m 37s\tremaining: 1m 17s\n",
            "86:\tlearn: 0.9977896\ttotal: 1m 38s\tremaining: 1m 16s\n",
            "87:\tlearn: 0.9977896\ttotal: 1m 40s\tremaining: 1m 15s\n",
            "88:\tlearn: 0.9977896\ttotal: 1m 41s\tremaining: 1m 13s\n",
            "89:\tlearn: 0.9977896\ttotal: 1m 42s\tremaining: 1m 12s\n",
            "90:\tlearn: 0.9977896\ttotal: 1m 43s\tremaining: 1m 11s\n",
            "91:\tlearn: 0.9977896\ttotal: 1m 44s\tremaining: 1m 10s\n",
            "92:\tlearn: 0.9977896\ttotal: 1m 45s\tremaining: 1m 9s\n",
            "93:\tlearn: 0.9977896\ttotal: 1m 46s\tremaining: 1m 8s\n",
            "94:\tlearn: 0.9977896\ttotal: 1m 47s\tremaining: 1m 6s\n",
            "95:\tlearn: 0.9977896\ttotal: 1m 48s\tremaining: 1m 5s\n",
            "96:\tlearn: 0.9977896\ttotal: 1m 49s\tremaining: 1m 4s\n",
            "97:\tlearn: 0.9977896\ttotal: 1m 51s\tremaining: 1m 3s\n",
            "98:\tlearn: 0.9977896\ttotal: 1m 52s\tremaining: 1m 2s\n",
            "99:\tlearn: 0.9977896\ttotal: 1m 53s\tremaining: 1m 1s\n",
            "100:\tlearn: 0.9977896\ttotal: 1m 54s\tremaining: 1m\n",
            "101:\tlearn: 0.9977896\ttotal: 1m 55s\tremaining: 58.9s\n",
            "102:\tlearn: 0.9978309\ttotal: 1m 56s\tremaining: 57.8s\n",
            "103:\tlearn: 0.9978309\ttotal: 1m 57s\tremaining: 56.6s\n",
            "104:\tlearn: 0.9978309\ttotal: 1m 58s\tremaining: 55.5s\n",
            "105:\tlearn: 0.9978309\ttotal: 1m 59s\tremaining: 54.3s\n",
            "106:\tlearn: 0.9979342\ttotal: 2m 1s\tremaining: 53.2s\n",
            "107:\tlearn: 0.9979342\ttotal: 2m 2s\tremaining: 52s\n",
            "108:\tlearn: 0.9979755\ttotal: 2m 3s\tremaining: 50.9s\n",
            "109:\tlearn: 0.9979755\ttotal: 2m 4s\tremaining: 49.8s\n",
            "110:\tlearn: 0.9979755\ttotal: 2m 5s\tremaining: 48.6s\n",
            "111:\tlearn: 0.9979755\ttotal: 2m 6s\tremaining: 47.5s\n",
            "112:\tlearn: 0.9979755\ttotal: 2m 7s\tremaining: 46.3s\n",
            "113:\tlearn: 0.9979755\ttotal: 2m 8s\tremaining: 45.2s\n",
            "114:\tlearn: 0.9980375\ttotal: 2m 9s\tremaining: 44s\n",
            "115:\tlearn: 0.9980375\ttotal: 2m 10s\tremaining: 42.9s\n",
            "116:\tlearn: 0.9980375\ttotal: 2m 12s\tremaining: 41.7s\n",
            "117:\tlearn: 0.9980375\ttotal: 2m 13s\tremaining: 40.6s\n",
            "118:\tlearn: 0.9980375\ttotal: 2m 14s\tremaining: 39.5s\n",
            "119:\tlearn: 0.9980375\ttotal: 2m 15s\tremaining: 38.3s\n",
            "120:\tlearn: 0.9980375\ttotal: 2m 16s\tremaining: 37.2s\n",
            "121:\tlearn: 0.9980375\ttotal: 2m 17s\tremaining: 36.1s\n",
            "122:\tlearn: 0.9980375\ttotal: 2m 18s\tremaining: 35s\n",
            "123:\tlearn: 0.9980375\ttotal: 2m 19s\tremaining: 33.8s\n",
            "124:\tlearn: 0.9980375\ttotal: 2m 20s\tremaining: 32.7s\n",
            "125:\tlearn: 0.9980375\ttotal: 2m 21s\tremaining: 31.6s\n",
            "126:\tlearn: 0.9980375\ttotal: 2m 23s\tremaining: 30.4s\n",
            "127:\tlearn: 0.9980375\ttotal: 2m 24s\tremaining: 29.3s\n",
            "128:\tlearn: 0.9980375\ttotal: 2m 25s\tremaining: 28.2s\n",
            "129:\tlearn: 0.9981615\ttotal: 2m 26s\tremaining: 27s\n",
            "130:\tlearn: 0.9981615\ttotal: 2m 27s\tremaining: 25.9s\n",
            "131:\tlearn: 0.9981615\ttotal: 2m 28s\tremaining: 24.8s\n",
            "132:\tlearn: 0.9981615\ttotal: 2m 29s\tremaining: 23.6s\n",
            "133:\tlearn: 0.9981615\ttotal: 2m 30s\tremaining: 22.5s\n",
            "134:\tlearn: 0.9981615\ttotal: 2m 31s\tremaining: 21.4s\n",
            "135:\tlearn: 0.9981615\ttotal: 2m 33s\tremaining: 20.3s\n",
            "136:\tlearn: 0.9981615\ttotal: 2m 34s\tremaining: 19.1s\n",
            "137:\tlearn: 0.9981615\ttotal: 2m 35s\tremaining: 18s\n",
            "138:\tlearn: 0.9982647\ttotal: 2m 36s\tremaining: 16.9s\n",
            "139:\tlearn: 0.9981201\ttotal: 2m 37s\tremaining: 15.7s\n",
            "140:\tlearn: 0.9985540\ttotal: 2m 38s\tremaining: 14.6s\n",
            "141:\tlearn: 0.9985126\ttotal: 2m 39s\tremaining: 13.5s\n",
            "142:\tlearn: 0.9985126\ttotal: 2m 40s\tremaining: 12.4s\n",
            "143:\tlearn: 0.9985540\ttotal: 2m 41s\tremaining: 11.2s\n",
            "144:\tlearn: 0.9985540\ttotal: 2m 43s\tremaining: 10.1s\n",
            "145:\tlearn: 0.9985540\ttotal: 2m 44s\tremaining: 8.99s\n",
            "146:\tlearn: 0.9986572\ttotal: 2m 45s\tremaining: 7.87s\n",
            "147:\tlearn: 0.9986572\ttotal: 2m 46s\tremaining: 6.74s\n",
            "148:\tlearn: 0.9986572\ttotal: 2m 47s\tremaining: 5.62s\n",
            "149:\tlearn: 0.9986572\ttotal: 2m 48s\tremaining: 4.49s\n",
            "150:\tlearn: 0.9986572\ttotal: 2m 49s\tremaining: 3.37s\n",
            "151:\tlearn: 0.9986572\ttotal: 2m 50s\tremaining: 2.25s\n",
            "152:\tlearn: 0.9986572\ttotal: 2m 51s\tremaining: 1.12s\n",
            "153:\tlearn: 0.9986572\ttotal: 2m 53s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f50dcd7b550>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1pQsvOK3BlF"
      },
      "source": [
        "predicted_vals = model_2.predict(np.array(test_inputs))\n"
      ],
      "id": "A1pQsvOK3BlF",
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8zee4cV3VUO",
        "outputId": "ea3778f7-27bd-49fb-b769-07cf10be86e3"
      },
      "source": [
        "from sklearn.metrics import classification_report, average_precision_score\n",
        "print(classification_report(test_df['Code_n'], predicted_vals))"
      ],
      "id": "z8zee4cV3VUO",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99        61\n",
            "           1       0.92      1.00      0.96        12\n",
            "           2       1.00      1.00      1.00         9\n",
            "           3       1.00      1.00      1.00         4\n",
            "           4       1.00      1.00      1.00         4\n",
            "           5       1.00      0.95      0.97        20\n",
            "           6       1.00      0.88      0.93         8\n",
            "           7       0.75      1.00      0.86         3\n",
            "           8       1.00      1.00      1.00         9\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         4\n",
            "          11       0.90      1.00      0.95        18\n",
            "          12       0.80      1.00      0.89         4\n",
            "          13       1.00      1.00      1.00        51\n",
            "          14       1.00      1.00      1.00        12\n",
            "          15       1.00      1.00      1.00         4\n",
            "          16       1.00      1.00      1.00         3\n",
            "          17       0.83      0.83      0.83         6\n",
            "          18       1.00      0.99      0.99       295\n",
            "          19       0.98      1.00      0.99        59\n",
            "          20       0.75      1.00      0.86         3\n",
            "          21       1.00      1.00      1.00         5\n",
            "          22       0.97      1.00      0.99        35\n",
            "          23       1.00      1.00      1.00         3\n",
            "          24       0.40      0.67      0.50         3\n",
            "          25       0.97      0.93      0.95        41\n",
            "          26       1.00      1.00      1.00        25\n",
            "          27       1.00      1.00      1.00        18\n",
            "          28       1.00      1.00      1.00        37\n",
            "          29       0.92      0.96      0.94        23\n",
            "          30       1.00      1.00      1.00        20\n",
            "          31       1.00      0.97      0.98       158\n",
            "          32       0.50      1.00      0.67         2\n",
            "          33       1.00      0.67      0.80         6\n",
            "          34       0.82      1.00      0.90        14\n",
            "          35       1.00      1.00      1.00         6\n",
            "          36       1.00      1.00      1.00         5\n",
            "          37       1.00      1.00      1.00       160\n",
            "          38       1.00      1.00      1.00         9\n",
            "          39       1.00      1.00      1.00         3\n",
            "          40       1.00      0.80      0.89         5\n",
            "          41       1.00      0.75      0.86         4\n",
            "          42       1.00      1.00      1.00        37\n",
            "          43       1.00      1.00      1.00         3\n",
            "          44       1.00      0.98      0.99        48\n",
            "          45       1.00      1.00      1.00        31\n",
            "          46       1.00      1.00      1.00         6\n",
            "          47       1.00      1.00      1.00         2\n",
            "          48       0.50      1.00      0.67         2\n",
            "\n",
            "    accuracy                           0.98      1302\n",
            "   macro avg       0.94      0.97      0.95      1302\n",
            "weighted avg       0.99      0.98      0.98      1302\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PO0LAzv5MuCm",
        "outputId": "61e9a121-b1ae-4e6f-bf69-4d0eb77a254a"
      },
      "source": [
        "# Stacking up\n",
        "from autogluon.text import TextPredictor\n",
        "predictor = TextPredictor(label='Code_n', path='ag_tabular_product_sentiment_text_predictor_20_epochs')\n",
        "predictor.fit(train_df, tuning_data=dev_df, hyperparameters={'epochs':20}, time_limit=2400)"
      ],
      "id": "PO0LAzv5MuCm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_tabular_product_sentiment_text_predictor_20_epochs\"\n",
            "Problem Type=\"multiclass\"\n",
            "Column Types:\n",
            "   - \"Dx\": text\n",
            "   - \"Code_n\": categorical\n",
            "\n",
            "The GluonNLP V0 backend is used. We will use 2 cpus and 1 gpus to train each trial.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Logs will be saved to /content/drive/Shareddrives/CS544 Project/notebooks/ag_tabular_product_sentiment_text_predictor_20_epochs/task0/training.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting and transforming the train data...\n",
            "Done! Preprocessor saved to /content/drive/Shareddrives/CS544 Project/notebooks/ag_tabular_product_sentiment_text_predictor_20_epochs/task0/preprocessor.pkl\n",
            "Process dev set...\n",
            "Done!\n",
            "Max length for chunking text: 64, Stochastic chunk: Train-False/Test-False, Test #repeat: 1.\n",
            "#Total Params/Fixed Params=108996529/0\n",
            "Using gradient accumulation. Global batch size = 128\n",
            "Local training results will be saved to /content/drive/Shareddrives/CS544 Project/notebooks/ag_tabular_product_sentiment_text_predictor_20_epochs/task0/results_local.jsonl.\n",
            "[Iter 19/3790, Epoch 0] train loss=4.16e+00, gnorm=6.36e+00, lr=5.01e-06, #samples processed=2432, #sample per second=62.33. ETA=129.06min\n",
            "[Iter 38/3790, Epoch 0] train loss=3.64e+00, gnorm=7.04e+00, lr=1.00e-05, #samples processed=2432, #sample per second=62.79. ETA=127.95min\n",
            "[Iter 57/3790, Epoch 0] train loss=2.83e+00, gnorm=7.89e+00, lr=1.50e-05, #samples processed=2432, #sample per second=62.45. ETA=127.38min\n",
            "[Iter 76/3790, Epoch 0] train loss=1.97e+00, gnorm=6.68e+00, lr=2.01e-05, #samples processed=2432, #sample per second=62.65. ETA=126.67min\n",
            "[Iter 76/3790, Epoch 0] valid accuracy=9.0323e-01, log_loss=1.1294e+00, time spent=5.986s, total time spent=2.75min. Find new best=True, Find new top-3=True\n",
            "[Iter 95/3790, Epoch 0] train loss=1.32e+00, gnorm=5.70e+00, lr=2.51e-05, #samples processed=2432, #sample per second=48.31. ETA=133.46min\n",
            "[Iter 114/3790, Epoch 0] train loss=7.83e-01, gnorm=3.76e+00, lr=3.01e-05, #samples processed=2432, #sample per second=63.31. ETA=131.29min\n",
            "[Iter 133/3790, Epoch 0] train loss=5.00e-01, gnorm=5.36e+00, lr=3.51e-05, #samples processed=2432, #sample per second=63.29. ETA=129.56min\n",
            "[Iter 152/3790, Epoch 0] train loss=3.50e-01, gnorm=2.96e+00, lr=4.01e-05, #samples processed=2432, #sample per second=62.32. ETA=128.35min\n",
            "[Iter 152/3790, Epoch 0] valid accuracy=9.3011e-01, log_loss=2.7754e-01, time spent=5.984s, total time spent=5.53min. Find new best=True, Find new top-3=True\n",
            "[Iter 171/3790, Epoch 0] train loss=2.21e-01, gnorm=2.31e+00, lr=4.51e-05, #samples processed=2432, #sample per second=48.08. ETA=131.33min\n",
            "[Iter 190/3790, Epoch 0] train loss=1.58e-01, gnorm=1.74e+00, lr=5.01e-05, #samples processed=2432, #sample per second=63.25. ETA=129.73min\n",
            "[Iter 209/3790, Epoch 0] train loss=1.10e-01, gnorm=1.07e+00, lr=5.51e-05, #samples processed=2432, #sample per second=62.98. ETA=128.34min\n",
            "[Iter 228/3790, Epoch 0] train loss=9.00e-02, gnorm=4.62e-01, lr=6.02e-05, #samples processed=2432, #sample per second=63.67. ETA=126.96min\n",
            "[Iter 228/3790, Epoch 0] valid accuracy=9.8694e-01, log_loss=9.1137e-02, time spent=5.901s, total time spent=8.29min. Find new best=True, Find new top-3=True\n",
            "[Iter 247/3790, Epoch 0] train loss=6.81e-02, gnorm=1.08e+00, lr=6.52e-05, #samples processed=2432, #sample per second=49.05. ETA=128.43min\n",
            "[Iter 266/3790, Epoch 0] train loss=6.08e-02, gnorm=5.91e-01, lr=7.02e-05, #samples processed=2432, #sample per second=63.47. ETA=127.08min\n",
            "[Iter 285/3790, Epoch 0] train loss=4.55e-02, gnorm=3.91e-01, lr=7.52e-05, #samples processed=2432, #sample per second=64.36. ETA=125.71min\n",
            "[Iter 304/3790, Epoch 0] train loss=3.94e-02, gnorm=2.27e-01, lr=8.02e-05, #samples processed=2432, #sample per second=63.29. ETA=124.56min\n",
            "[Iter 304/3790, Epoch 0] valid accuracy=9.9002e-01, log_loss=6.1716e-02, time spent=5.897s, total time spent=11.02min. Find new best=True, Find new top-3=True\n",
            "[Iter 323/3790, Epoch 0] train loss=4.23e-02, gnorm=6.99e-01, lr=8.52e-05, #samples processed=2432, #sample per second=48.62. ETA=125.54min\n",
            "[Iter 342/3790, Epoch 0] train loss=2.92e-02, gnorm=1.49e-01, lr=9.02e-05, #samples processed=2432, #sample per second=63.55. ETA=124.35min\n",
            "[Iter 361/3790, Epoch 0] train loss=2.48e-02, gnorm=1.19e-01, lr=9.53e-05, #samples processed=2432, #sample per second=64.01. ETA=123.17min\n",
            "[Iter 380/3790, Epoch 1] train loss=2.73e-02, gnorm=6.56e-01, lr=1.00e-04, #samples processed=2432, #sample per second=63.83. ETA=122.07min\n",
            "[Iter 380/3790, Epoch 1] valid accuracy=9.9155e-01, log_loss=4.9268e-02, time spent=5.932s, total time spent=13.76min. Find new best=True, Find new top-3=True\n",
            "[Iter 399/3790, Epoch 1] train loss=1.79e-02, gnorm=9.97e-02, lr=9.94e-05, #samples processed=2432, #sample per second=48.87. ETA=122.65min\n",
            "[Iter 418/3790, Epoch 1] train loss=2.03e-02, gnorm=3.89e-01, lr=9.89e-05, #samples processed=2432, #sample per second=63.43. ETA=121.58min\n",
            "[Iter 437/3790, Epoch 1] train loss=1.85e-02, gnorm=8.67e-02, lr=9.83e-05, #samples processed=2432, #sample per second=63.31. ETA=120.55min\n",
            "[Iter 456/3790, Epoch 1] train loss=1.43e-02, gnorm=8.37e-02, lr=9.77e-05, #samples processed=2432, #sample per second=63.85. ETA=119.52min\n",
            "[Iter 456/3790, Epoch 1] valid accuracy=9.9155e-01, log_loss=5.1346e-02, time spent=5.947s, total time spent=16.51min. Find new best=True, Find new top-3=True\n",
            "[Iter 475/3790, Epoch 1] train loss=1.52e-02, gnorm=1.04e-01, lr=9.72e-05, #samples processed=2432, #sample per second=48.74. ETA=119.89min\n",
            "[Iter 494/3790, Epoch 1] train loss=1.28e-02, gnorm=5.30e-02, lr=9.66e-05, #samples processed=2432, #sample per second=63.11. ETA=118.90min\n",
            "[Iter 513/3790, Epoch 1] train loss=1.30e-02, gnorm=4.75e-02, lr=9.61e-05, #samples processed=2432, #sample per second=62.87. ETA=117.96min\n",
            "[Iter 532/3790, Epoch 1] train loss=1.55e-02, gnorm=4.04e-02, lr=9.55e-05, #samples processed=2432, #sample per second=63.42. ETA=117.00min\n",
            "[Iter 532/3790, Epoch 1] valid accuracy=9.9232e-01, log_loss=4.5762e-02, time spent=5.907s, total time spent=19.26min. Find new best=True, Find new top-3=True\n",
            "[Iter 551/3790, Epoch 1] train loss=1.33e-02, gnorm=4.82e-02, lr=9.50e-05, #samples processed=2432, #sample per second=48.70. ETA=117.20min\n",
            "[Iter 570/3790, Epoch 1] train loss=1.01e-02, gnorm=3.16e-02, lr=9.44e-05, #samples processed=2432, #sample per second=63.97. ETA=116.21min\n",
            "[Iter 589/3790, Epoch 1] train loss=1.09e-02, gnorm=3.41e-02, lr=9.38e-05, #samples processed=2432, #sample per second=63.13. ETA=115.28min\n",
            "[Iter 608/3790, Epoch 1] train loss=1.29e-02, gnorm=6.39e-02, lr=9.33e-05, #samples processed=2432, #sample per second=63.50. ETA=114.36min\n",
            "[Iter 608/3790, Epoch 1] valid accuracy=9.9155e-01, log_loss=5.2629e-02, time spent=5.917s, total time spent=21.98min. Find new best=False, Find new top-3=True\n",
            "[Iter 627/3790, Epoch 1] train loss=1.21e-02, gnorm=5.27e-02, lr=9.27e-05, #samples processed=2432, #sample per second=51.70. ETA=114.19min\n",
            "[Iter 646/3790, Epoch 1] train loss=9.51e-03, gnorm=6.40e-02, lr=9.22e-05, #samples processed=2432, #sample per second=62.57. ETA=113.32min\n",
            "[Iter 665/3790, Epoch 1] train loss=1.08e-02, gnorm=8.48e-02, lr=9.16e-05, #samples processed=2432, #sample per second=63.35. ETA=112.42min\n",
            "[Iter 684/3790, Epoch 1] train loss=9.35e-03, gnorm=2.22e-02, lr=9.11e-05, #samples processed=2432, #sample per second=63.28. ETA=111.54min\n",
            "[Iter 684/3790, Epoch 1] valid accuracy=9.9232e-01, log_loss=4.8326e-02, time spent=6.021s, total time spent=24.73min. Find new best=True, Find new top-3=True\n",
            "[Iter 703/3790, Epoch 1] train loss=8.31e-03, gnorm=7.37e-01, lr=9.05e-05, #samples processed=2432, #sample per second=48.27. ETA=111.55min\n",
            "[Iter 722/3790, Epoch 1] train loss=9.60e-03, gnorm=4.04e-02, lr=8.99e-05, #samples processed=2432, #sample per second=63.00. ETA=110.68min\n",
            "[Iter 741/3790, Epoch 1] train loss=1.06e-02, gnorm=5.71e-02, lr=8.94e-05, #samples processed=2432, #sample per second=63.40. ETA=109.81min\n",
            "[Iter 760/3790, Epoch 2] train loss=7.50e-03, gnorm=1.99e-01, lr=8.88e-05, #samples processed=2432, #sample per second=63.39. ETA=108.94min\n",
            "[Iter 760/3790, Epoch 2] valid accuracy=9.9155e-01, log_loss=5.6563e-02, time spent=5.947s, total time spent=27.46min. Find new best=False, Find new top-3=True\n",
            "[Iter 779/3790, Epoch 2] train loss=7.34e-03, gnorm=2.81e-02, lr=8.83e-05, #samples processed=2432, #sample per second=51.99. ETA=108.64min\n",
            "[Iter 798/3790, Epoch 2] train loss=1.15e-02, gnorm=1.99e-01, lr=8.77e-05, #samples processed=2432, #sample per second=63.40. ETA=107.78min\n",
            "[Iter 817/3790, Epoch 2] train loss=5.57e-03, gnorm=2.79e-02, lr=8.72e-05, #samples processed=2432, #sample per second=63.75. ETA=106.92min\n",
            "[Iter 836/3790, Epoch 2] train loss=7.78e-03, gnorm=1.95e-01, lr=8.66e-05, #samples processed=2432, #sample per second=63.64. ETA=106.07min\n",
            "[Iter 836/3790, Epoch 2] valid accuracy=9.9232e-01, log_loss=5.3184e-02, time spent=5.953s, total time spent=30.18min. Find new best=True, Find new top-3=True\n",
            "[Iter 855/3790, Epoch 2] train loss=6.46e-03, gnorm=1.77e-02, lr=8.60e-05, #samples processed=2432, #sample per second=49.33. ETA=105.87min\n",
            "[Iter 874/3790, Epoch 2] train loss=5.51e-03, gnorm=2.46e-02, lr=8.55e-05, #samples processed=2432, #sample per second=63.28. ETA=105.03min\n",
            "[Iter 893/3790, Epoch 2] train loss=8.46e-03, gnorm=3.26e-02, lr=8.49e-05, #samples processed=2432, #sample per second=64.03. ETA=104.18min\n",
            "[Iter 912/3790, Epoch 2] train loss=8.17e-03, gnorm=5.70e-02, lr=8.44e-05, #samples processed=2432, #sample per second=63.82. ETA=103.35min\n",
            "[Iter 912/3790, Epoch 2] valid accuracy=9.9232e-01, log_loss=5.0268e-02, time spent=5.927s, total time spent=32.91min. Find new best=True, Find new top-3=True\n",
            "[Iter 931/3790, Epoch 2] train loss=9.67e-03, gnorm=2.21e-02, lr=8.38e-05, #samples processed=2432, #sample per second=48.82. ETA=103.12min\n",
            "[Iter 950/3790, Epoch 2] train loss=9.18e-03, gnorm=4.44e-02, lr=8.33e-05, #samples processed=2432, #sample per second=64.21. ETA=102.27min\n",
            "[Iter 969/3790, Epoch 2] train loss=1.21e-02, gnorm=1.21e-01, lr=8.27e-05, #samples processed=2432, #sample per second=63.19. ETA=101.46min\n",
            "[Iter 988/3790, Epoch 2] train loss=7.72e-03, gnorm=1.16e-01, lr=8.21e-05, #samples processed=2432, #sample per second=63.22. ETA=100.66min\n",
            "[Iter 988/3790, Epoch 2] valid accuracy=9.9078e-01, log_loss=6.0149e-02, time spent=5.938s, total time spent=35.59min. Find new best=False, Find new top-3=False\n",
            "[Iter 1007/3790, Epoch 2] train loss=7.56e-03, gnorm=2.24e-02, lr=8.16e-05, #samples processed=2432, #sample per second=54.77. ETA=100.14min\n",
            "[Iter 1026/3790, Epoch 2] train loss=5.79e-03, gnorm=1.37e-02, lr=8.10e-05, #samples processed=2432, #sample per second=64.04. ETA=99.32min\n",
            "[Iter 1045/3790, Epoch 2] train loss=7.25e-03, gnorm=2.19e-02, lr=8.05e-05, #samples processed=2432, #sample per second=64.03. ETA=98.50min\n",
            "[Iter 1064/3790, Epoch 2] train loss=6.57e-03, gnorm=4.29e-01, lr=7.99e-05, #samples processed=2432, #sample per second=63.98. ETA=97.70min\n",
            "[Iter 1064/3790, Epoch 2] valid accuracy=9.9309e-01, log_loss=5.1289e-02, time spent=5.908s, total time spent=38.29min. Find new best=True, Find new top-3=True\n",
            "[Iter 1083/3790, Epoch 2] train loss=3.69e-03, gnorm=1.81e-02, lr=7.94e-05, #samples processed=2432, #sample per second=49.80. ETA=97.35min\n",
            "[Iter 1102/3790, Epoch 2] train loss=7.73e-03, gnorm=1.35e-02, lr=7.88e-05, #samples processed=2432, #sample per second=63.34. ETA=96.56min\n",
            "[Iter 1121/3790, Epoch 2] train loss=7.24e-03, gnorm=4.55e-02, lr=7.82e-05, #samples processed=2432, #sample per second=63.44. ETA=95.78min\n",
            "[Iter 1140/3790, Epoch 3] train loss=8.37e-03, gnorm=1.95e-02, lr=7.77e-05, #samples processed=2432, #sample per second=62.70. ETA=95.01min\n",
            "[Iter 1140/3790, Epoch 3] valid accuracy=9.9232e-01, log_loss=5.0193e-02, time spent=5.962s, total time spent=41.00min. Find new best=False, Find new top-3=True\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training completed. Auto-saving to \"ag_tabular_product_sentiment_text_predictor_20_epochs/\". For loading the model, you can use `predictor = TextPredictor.load(\"ag_tabular_product_sentiment_text_predictor_20_epochs/\")`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<autogluon.text.text_prediction.predictor.predictor.TextPredictor at 0x7fe52ae7fb50>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "Q0TcdH41f5wW",
        "outputId": "ca3b0df1-7ed8-4ec7-8cf6-01c61a9c277e"
      },
      "source": [
        "c"
      ],
      "id": "Q0TcdH41f5wW",
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2b66fd261ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "6TKnZ1UQRyOa",
        "outputId": "79fb0f8e-fe29-47d7-e702-7c59b072c18e"
      },
      "source": [
        "!pip install torch==1.8.0"
      ],
      "id": "6TKnZ1UQRyOa",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch==1.8.0\n",
            "  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.10.0.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWvlzQgqS6f2",
        "outputId": "1e7eefa7-322f-4dba-dd59-cc40b7c6be64"
      },
      "source": [
        "!pip install torchvision==0.9.0"
      ],
      "id": "OWvlzQgqS6f2",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchvision==0.9.0\n",
            "  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 116 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0) (8.3.2)\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0) (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchvision==0.9.0) (3.10.0.2)\n",
            "Installing collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "Successfully installed torchvision-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZc1OR0hTAZH",
        "outputId": "000d1966-aeab-48c2-da07-5c9b39c69c82"
      },
      "source": [
        "!pip install autogluon"
      ],
      "id": "hZc1OR0hTAZH",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autogluon in /usr/local/lib/python3.7/dist-packages (0.3.1)\n",
            "Requirement already satisfied: autogluon.extra==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n",
            "Requirement already satisfied: autogluon.core==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n",
            "Requirement already satisfied: autogluon.tabular[all]==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n",
            "Requirement already satisfied: autogluon.mxnet==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n",
            "Requirement already satisfied: autogluon.features==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n",
            "Requirement already satisfied: autogluon.vision==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n",
            "Requirement already satisfied: autogluon.text==0.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon) (0.3.1)\n",
            "Requirement already satisfied: dill<1.0,>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.3.4)\n",
            "Requirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2021.11.2)\n",
            "Requirement already satisfied: numpy<1.22,>=1.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.19.5)\n",
            "Requirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.1.5)\n",
            "Requirement already satisfied: scipy<1.7,>=1.5.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2.23.0)\n",
            "Requirement already satisfied: ConfigSpace==0.4.19 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.4.19)\n",
            "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (4.62.3)\n",
            "Requirement already satisfied: graphviz<1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.8.4)\n",
            "Requirement already satisfied: paramiko>=2.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2.8.0)\n",
            "Requirement already satisfied: distributed>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (2021.11.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.20.14)\n",
            "Requirement already satisfied: scikit-learn<0.25,>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.24.2)\n",
            "Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (5.1.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (3.2.2)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (0.29.24)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.3.1->autogluon) (1.3)\n",
            "Requirement already satisfied: openml in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.1->autogluon) (0.12.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.1->autogluon) (3.6.4)\n",
            "Requirement already satisfied: gluoncv<0.10.5,>=0.10.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.3.1->autogluon) (0.10.4.post4)\n",
            "Requirement already satisfied: Pillow<8.4.0,>=8.3.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.mxnet==0.3.1->autogluon) (8.3.2)\n",
            "Requirement already satisfied: psutil<5.9,>=5.7.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (5.8.0)\n",
            "Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (2.6.3)\n",
            "Requirement already satisfied: xgboost<1.5,>=1.4 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (1.4.2)\n",
            "Requirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (1.8.0)\n",
            "Requirement already satisfied: lightgbm<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (3.3.1)\n",
            "Requirement already satisfied: catboost<0.26,>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (0.25.1)\n",
            "Requirement already satisfied: fastai<3.0,>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.3.1->autogluon) (2.5.3)\n",
            "Requirement already satisfied: autogluon-contrib-nlp==0.0.1b20210201 in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.3.1->autogluon) (0.0.1b20210201)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Using cached tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.0.0)\n",
            "Requirement already satisfied: sacremoses>=0.0.38 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.0.46)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (4.0.1)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.1.95)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.17.3)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.1.8)\n",
            "Requirement already satisfied: contextvars in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (3.0.0)\n",
            "Requirement already satisfied: d8<1.0,>=0.0.2 in /usr/local/lib/python3.7/dist-packages (from autogluon.vision==0.3.1->autogluon) (0.0.2.post0)\n",
            "Requirement already satisfied: timm-clean==0.4.12 in /usr/local/lib/python3.7/dist-packages (from autogluon.vision==0.3.1->autogluon) (0.4.12)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.19->autogluon.core==0.3.1->autogluon) (3.0.6)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.3.1->autogluon) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (4.4.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (2.0.2)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (1.5.12)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (1.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (6.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (2021.11.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask>=2.6.0->autogluon.core==0.3.1->autogluon) (0.11.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.7.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.11.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (57.4.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (7.1.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.0)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.0.5)\n",
            "Requirement already satisfied: fastcore<1.4,>=1.3.22 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.3.27)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (21.1.3)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.9.0)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.2.4)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.1->autogluon) (2.3.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.1->autogluon) (4.1.2.30)\n",
            "Requirement already satisfied: autocfg in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.10.5,>=0.10.4->autogluon.extra==0.3.1->autogluon) (0.0.8)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.3.1->autogluon) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.3.1->autogluon) (2018.9)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.1->autogluon) (36.0.0)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.1->autogluon) (1.4.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko>=2.4->autogluon.core==0.3.1->autogluon) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.3.1->autogluon) (2.21)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask>=2.6.0->autogluon.core==0.3.1->autogluon) (0.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses>=0.0.38->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.3.1->autogluon) (3.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.0.6)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (2.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<4->fastai<3.0,>=2.3.1->autogluon.tabular[all]==0.3.1->autogluon) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.3.1->autogluon) (2021.10.8)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.24.0,>=1.23.14 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.1->autogluon) (1.23.14)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.1->autogluon) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->autogluon.core==0.3.1->autogluon) (0.5.0)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.7/dist-packages (from contextvars->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.16)\n",
            "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.4.0)\n",
            "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (2.8.0)\n",
            "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2.6.0->autogluon.core==0.3.1->autogluon) (2.0.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (5.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.3.1->autogluon) (0.11.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.1->autogluon) (0.12.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.1->autogluon) (2.5.0)\n",
            "Requirement already satisfied: minio in /usr/local/lib/python3.7/dist-packages (from openml->autogluon.extra==0.3.1->autogluon) (7.1.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.3.1->autogluon) (1.3.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (21.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.3.1->autogluon) (8.11.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.3.1->autogluon) (1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.8.9)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.3.1->autogluon) (0.4.4)\n",
            "Installing collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.10.3\n",
            "    Uninstalling tokenizers-0.10.3:\n",
            "      Successfully uninstalled tokenizers-0.10.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 4.12.5 requires tokenizers<0.11,>=0.10.1, but you have tokenizers 0.9.4 which is incompatible.\u001b[0m\n",
            "Successfully installed tokenizers-0.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y94biERPT0Ni"
      },
      "source": [
        "import torch"
      ],
      "id": "Y94biERPT0Ni",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxwtigDAT2PA",
        "outputId": "482525b4-35bb-44e2-80af-ecede836c9d2"
      },
      "source": [
        "import torch \n",
        "print(torch.__version__)\n"
      ],
      "id": "oxwtigDAT2PA",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI_-d4QjWyg8",
        "outputId": "de181352-89e8-4743-b5d9-6829873e1711"
      },
      "source": [
        "x_train"
      ],
      "id": "AI_-d4QjWyg8",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  101, 23245,  2389,  ...,     0,     0,     0],\n",
              "        [  101, 17503,  2482,  ...,     0,     0,     0],\n",
              "        [  101, 23245,  2389,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101, 10930, 13687,  ...,     0,     0,     0],\n",
              "        [  101, 10930, 13687,  ...,     0,     0,     0],\n",
              "        [  101, 10930, 13687,  ...,     0,     0,     0]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0QubjyjciPD",
        "outputId": "e640471e-e327-4907-ca38-950200e81d95"
      },
      "source": [
        "y_train.shape, y_dev.shape, attention_mask_dev.shape, attention_mask_test.shape, attention_mask_train.shape"
      ],
      "id": "r0QubjyjciPD",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((47963,), (15386,), (15386, 34), (1302, 34), (47963, 34))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLMSLPGsbFMM"
      },
      "source": [
        "#Format X, Y for input into NN: (For Dataloader)\n",
        "train_data = []\n",
        "for i in range(len(x_train)):\n",
        "    train_data.append([attention_mask_train[i],x_train[i], y_train[i]])\n",
        "    \n",
        "dev_data = []\n",
        "for i in range(len(x_dev)):\n",
        "    dev_data.append([attention_mask_dev[i],x_dev[i], y_dev[i]])"
      ],
      "id": "DLMSLPGsbFMM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HurT2eYc7oQv"
      },
      "source": [
        "y_train = torch.tensor(y_train)\n",
        "y_dev = torch.tensor(y_dev)"
      ],
      "id": "HurT2eYc7oQv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5z8Je_1dDrt",
        "outputId": "68ec6c3a-5d0f-4728-eba7-2266341e41cc"
      },
      "source": [
        "x_dev.shape"
      ],
      "id": "-5z8Je_1dDrt",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([15386, 34])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3151444"
      },
      "source": [
        "# Classifying"
      ],
      "id": "d3151444"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4740f2c9"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch import nn"
      ],
      "id": "4740f2c9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-vmWXh277UV"
      },
      "source": [
        "attention_mask_train = torch.tensor(attention_mask_train)\n",
        "attention_mask_dev = torch.tensor(attention_mask_dev)"
      ],
      "id": "T-vmWXh277UV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3CP5KGM5YX-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(x_train, attention_mask_train, y_train)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(x_dev, attention_mask_dev, y_dev)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n",
        "test_data = TensorDataset(x_test, attention_mask_test, y_test)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)\n"
      ],
      "id": "U3CP5KGM5YX-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXmWwC7JWpkP"
      },
      "source": [
        "y_test = torch.tensor(y_test)\n",
        "attention_mask_test = torch.tensor(attention_mask_test)\n",
        "test_data = TensorDataset(x_test, attention_mask_test, y_test)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "test_dataloader = DataLoader(test_data, sampler = test_sampler, batch_size=batch_size)\n"
      ],
      "id": "aXmWwC7JWpkP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWX-unwK8KHx"
      },
      "source": [
        "# Try once without these:\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "id": "xWX-unwK8KHx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpLK1F828q02"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,49)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict = False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "id": "lpLK1F828q02",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd1geQN4XCdm",
        "outputId": "9c00e10f-ba4d-4554-cf99-931e33e6931d"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "device"
      ],
      "id": "vd1geQN4XCdm",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLNQVzve8rxt"
      },
      "source": [
        "model_t = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model_t.to(device)"
      ],
      "id": "YLNQVzve8rxt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqlCusSu8y1R"
      },
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5)  "
      ],
      "id": "mqlCusSu8y1R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSI9AkVo8374"
      },
      "source": [
        "cross_entropy  = nn.NLLLoss() \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ],
      "id": "oSI9AkVo8374",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfE4K-6o9fXL"
      },
      "source": [
        "def train():\n",
        "  \n",
        "  model_t.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "id": "jfE4K-6o9fXL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLaJJ6e09qGm"
      },
      "source": [
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      # elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "id": "gLaJJ6e09qGm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nCqVWyjj95gv",
        "outputId": "7b77b802-fdbc-4dea-f9db-a48fa1f733c8"
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(50):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "id": "nCqVWyjj95gv",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.701\n",
            "Validation Loss: 2.265\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.601\n",
            "Validation Loss: 2.152\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.514\n",
            "Validation Loss: 2.059\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.420\n",
            "Validation Loss: 1.954\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.341\n",
            "Validation Loss: 1.847\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.260\n",
            "Validation Loss: 1.767\n",
            "\n",
            " Epoch 7 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.177\n",
            "Validation Loss: 1.676\n",
            "\n",
            " Epoch 8 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.106\n",
            "Validation Loss: 1.605\n",
            "\n",
            " Epoch 9 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 2.035\n",
            "Validation Loss: 1.545\n",
            "\n",
            " Epoch 10 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.962\n",
            "Validation Loss: 1.457\n",
            "\n",
            " Epoch 11 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.901\n",
            "Validation Loss: 1.394\n",
            "\n",
            " Epoch 12 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.833\n",
            "Validation Loss: 1.339\n",
            "\n",
            " Epoch 13 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.765\n",
            "Validation Loss: 1.275\n",
            "\n",
            " Epoch 14 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.707\n",
            "Validation Loss: 1.209\n",
            "\n",
            " Epoch 15 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.650\n",
            "Validation Loss: 1.166\n",
            "\n",
            " Epoch 16 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.594\n",
            "Validation Loss: 1.102\n",
            "\n",
            " Epoch 17 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.537\n",
            "Validation Loss: 1.057\n",
            "\n",
            " Epoch 18 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.494\n",
            "Validation Loss: 1.007\n",
            "\n",
            " Epoch 19 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.441\n",
            "Validation Loss: 0.962\n",
            "\n",
            " Epoch 20 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.395\n",
            "Validation Loss: 0.932\n",
            "\n",
            " Epoch 21 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.355\n",
            "Validation Loss: 0.876\n",
            "\n",
            " Epoch 22 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.311\n",
            "Validation Loss: 0.860\n",
            "\n",
            " Epoch 23 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.270\n",
            "Validation Loss: 0.816\n",
            "\n",
            " Epoch 24 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.232\n",
            "Validation Loss: 0.795\n",
            "\n",
            " Epoch 25 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.196\n",
            "Validation Loss: 0.762\n",
            "\n",
            " Epoch 26 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.159\n",
            "Validation Loss: 0.732\n",
            "\n",
            " Epoch 27 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.123\n",
            "Validation Loss: 0.693\n",
            "\n",
            " Epoch 28 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n",
            "  Batch 1,050  of  1,499.\n",
            "  Batch 1,100  of  1,499.\n",
            "  Batch 1,150  of  1,499.\n",
            "  Batch 1,200  of  1,499.\n",
            "  Batch 1,250  of  1,499.\n",
            "  Batch 1,300  of  1,499.\n",
            "  Batch 1,350  of  1,499.\n",
            "  Batch 1,400  of  1,499.\n",
            "  Batch 1,450  of  1,499.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    481.\n",
            "  Batch   100  of    481.\n",
            "  Batch   150  of    481.\n",
            "  Batch   200  of    481.\n",
            "  Batch   250  of    481.\n",
            "  Batch   300  of    481.\n",
            "  Batch   350  of    481.\n",
            "  Batch   400  of    481.\n",
            "  Batch   450  of    481.\n",
            "\n",
            "Training Loss: 1.092\n",
            "Validation Loss: 0.666\n",
            "\n",
            " Epoch 29 / 10\n",
            "  Batch    50  of  1,499.\n",
            "  Batch   100  of  1,499.\n",
            "  Batch   150  of  1,499.\n",
            "  Batch   200  of  1,499.\n",
            "  Batch   250  of  1,499.\n",
            "  Batch   300  of  1,499.\n",
            "  Batch   350  of  1,499.\n",
            "  Batch   400  of  1,499.\n",
            "  Batch   450  of  1,499.\n",
            "  Batch   500  of  1,499.\n",
            "  Batch   550  of  1,499.\n",
            "  Batch   600  of  1,499.\n",
            "  Batch   650  of  1,499.\n",
            "  Batch   700  of  1,499.\n",
            "  Batch   750  of  1,499.\n",
            "  Batch   800  of  1,499.\n",
            "  Batch   850  of  1,499.\n",
            "  Batch   900  of  1,499.\n",
            "  Batch   950  of  1,499.\n",
            "  Batch 1,000  of  1,499.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-a821b7ab428a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-35c50ae3eee4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# add on to the total loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# backward pass to calculate the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-N9kkTjU3CF",
        "outputId": "90bc5835-fa61-4caa-8f63-12a7c29e1167"
      },
      "source": [
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "id": "W-N9kkTjU3CF",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkjb48pfVCR0"
      },
      "source": [
        "with torch.no_grad():\n",
        "  preds = model(x_test.to(device), attention_mask_test.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "id": "qkjb48pfVCR0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKL2XFY2XDI1"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "id": "cKL2XFY2XDI1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQS2XwbUVVgu",
        "outputId": "6a26ef2f-0c91-4af7-e65d-1c0a3eaad7c2"
      },
      "source": [
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(y_test, preds))"
      ],
      "id": "oQS2XwbUVVgu",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.68      0.69        62\n",
            "           1       0.67      0.75      0.71         8\n",
            "           2       0.33      0.60      0.43         5\n",
            "           3       0.56      1.00      0.71         5\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.68      0.87      0.76        15\n",
            "           6       0.25      0.62      0.36         8\n",
            "           7       0.80      0.67      0.73         6\n",
            "           8       0.62      0.89      0.73         9\n",
            "           9       0.50      1.00      0.67         2\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       0.57      0.35      0.43        23\n",
            "          12       0.62      0.83      0.71         6\n",
            "          13       0.87      0.81      0.84        42\n",
            "          14       0.21      0.75      0.32         8\n",
            "          15       0.50      1.00      0.67         4\n",
            "          16       0.27      0.75      0.40         4\n",
            "          17       0.64      0.90      0.75        10\n",
            "          18       0.99      0.68      0.81       307\n",
            "          19       0.54      0.76      0.63        58\n",
            "          20       0.43      0.60      0.50         5\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.64      0.77      0.70        30\n",
            "          23       0.43      1.00      0.60         3\n",
            "          24       0.18      1.00      0.31         2\n",
            "          25       1.00      0.69      0.82        36\n",
            "          26       0.76      0.70      0.73        23\n",
            "          27       0.44      0.39      0.41        18\n",
            "          28       0.86      0.76      0.81        33\n",
            "          29       0.50      0.56      0.53        18\n",
            "          30       0.62      0.94      0.75        16\n",
            "          31       0.84      0.69      0.76       163\n",
            "          32       0.50      1.00      0.67         2\n",
            "          33       0.00      0.00      0.00         3\n",
            "          34       0.80      0.92      0.86        13\n",
            "          35       0.80      1.00      0.89         4\n",
            "          36       1.00      1.00      1.00         1\n",
            "          37       0.89      0.69      0.77       170\n",
            "          38       0.70      0.93      0.80        15\n",
            "          39       0.36      0.83      0.50         6\n",
            "          40       0.18      1.00      0.31         2\n",
            "          41       0.33      0.50      0.40         2\n",
            "          42       1.00      0.98      0.99        45\n",
            "          43       0.11      0.67      0.19         3\n",
            "          44       0.95      0.78      0.86        50\n",
            "          45       1.00      0.69      0.82        36\n",
            "          46       0.40      1.00      0.57         4\n",
            "          47       0.58      1.00      0.74         7\n",
            "          48       0.50      0.20      0.29         5\n",
            "\n",
            "    accuracy                           0.72      1302\n",
            "   macro avg       0.57      0.74      0.61      1302\n",
            "weighted avg       0.82      0.72      0.75      1302\n",
            "\n"
          ]
        }
      ]
    }
  ]
}